{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multilabel-classification Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model development with TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import hamming_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TF-IDF Model for Contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pre_process_data(df, test_proportion=0.1):\n",
        "\n",
        "    df.columns.values[0] = \"FQText\"\n",
        "    size_df = df.shape[0]\n",
        "\n",
        "    X = df[[\"FQText\"]].to_numpy()\n",
        "\n",
        "    y_df = df.drop([\"FQText\"], axis=1).astype(np.float32)\n",
        "    cols = df.columns\n",
        "    df_labels = list(y_df.columns)\n",
        "\n",
        "    y = y_df.to_numpy()\n",
        "\n",
        "    X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size=test_proportion)\n",
        "    \n",
        "    X_train = pd.DataFrame(X_train, columns=[\"FQText\"])\n",
        "    y_train = pd.DataFrame(y_train, columns=[df_labels], dtype=np.float32)\n",
        "    X_test = pd.DataFrame(X_test, columns=[\"FQText\"])\n",
        "    y_test = pd.DataFrame(y_test, columns=[df_labels], dtype=np.float32)\n",
        "\n",
        "    # print(df_labels)\n",
        "\n",
        "    # print(\"Total amount of data: {}\".format(size_df))\n",
        "    # print(\"Number of rows used to TRAIN: {}\".format(X_train.shape[0]))\n",
        "    # print(\"Number of rows used to TEST: {}\".format(X_test.shape[0]))\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, df_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfs = ['nancy_determinants_individual_labels_eng.csv',\n",
        " 'nancy_contents_individual_labels_eng.csv',\n",
        " 'nancy_contents_macro_labels_english.csv',\n",
        " 'nancy_determinants_macro_labels_english.csv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = [KNeighborsClassifier(random_state=42), LogisticRegression(random_state=42, solver = \"sag\"), SVC(random_state=42), \n",
        "          RandomForestClassifier(random_state=42), SGDClassifier(random_state=42), GradientBoostingClassifier(random_state=42)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_tfidf(df_name, models=models):\n",
        "    \n",
        "    name = \"_\".join(df_name.split(\"_\")[1:3])\n",
        "    df = pd.read_csv(df_name)\n",
        "\n",
        "    X_train, y_train, X_test, y_test, df_labels = pre_process_data(df, test_proportion=0.1)\n",
        "\n",
        "    tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "    X_train_transformed = tfidf_vectorizer.fit_transform(X_train[\"FQText\"].to_list())\n",
        "    X_test_transformed = tfidf_vectorizer.transform(X_test[\"FQText\"].to_list())\n",
        "    \n",
        "    list_results = []\n",
        "\n",
        "    for model in models:\n",
        "        model_name = str(model).split(\"()\")[0]\n",
        "        dict_model_info = {\"data_model\": name,\n",
        "                            \"labels\": df_labels,\n",
        "                            \"ml_algo\":model_name}\n",
        "        one_v_rest = OneVsRestClassifier(model)\n",
        "\n",
        "        model_fit = one_v_rest.fit(X_train_transformed, y_train)\n",
        "\n",
        "        y_pred = model_fit.predict(X_test_transformed)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
        "        hamming = hamming_loss(y_test, y_pred)\n",
        "        \n",
        "        dict_model_info[\"accuracy\"] = accuracy\n",
        "        dict_model_info[\"f1\"] = f1\n",
        "        dict_model_info[\"hamming\"] = hamming\n",
        "        \n",
        "        list_results.append(dict_model_info)\n",
        "    return list_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for df in dfs:\n",
        "    results_per_df = model_tfidf(df)\n",
        "    results.extend(results_per_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results for the TF-IDF Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_tf = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_model</th>\n",
              "      <th>labels</th>\n",
              "      <th>ml_algo</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>hamming</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.650602</td>\n",
              "      <td>0.062771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.075758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.210526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.441176</td>\n",
              "      <td>0.082251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.261905</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.088745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='sag')</td>\n",
              "      <td>0.261905</td>\n",
              "      <td>0.393443</td>\n",
              "      <td>0.080087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>SVC</td>\n",
              "      <td>0.261905</td>\n",
              "      <td>0.393443</td>\n",
              "      <td>0.080087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.385542</td>\n",
              "      <td>0.268421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.186047</td>\n",
              "      <td>0.371429</td>\n",
              "      <td>0.037898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.221053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.337662</td>\n",
              "      <td>0.268421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.186047</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.051680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.242424</td>\n",
              "      <td>0.043066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='sag')</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.226415</td>\n",
              "      <td>0.215789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.078947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>0.067251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.046512</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.041344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.076023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.070175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>SVC</td>\n",
              "      <td>0.046512</td>\n",
              "      <td>0.109091</td>\n",
              "      <td>0.042205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>SVC</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.081633</td>\n",
              "      <td>0.236842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='sag')</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.064327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>SVC</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.042553</td>\n",
              "      <td>0.065789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='sag')</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 data_model  \\\n",
              "16           contents_macro   \n",
              "12           contents_macro   \n",
              "23       determinants_macro   \n",
              "17           contents_macro   \n",
              "15           contents_macro   \n",
              "13           contents_macro   \n",
              "14           contents_macro   \n",
              "22       determinants_macro   \n",
              "11      contents_individual   \n",
              "21       determinants_macro   \n",
              "18       determinants_macro   \n",
              "10      contents_individual   \n",
              "6       contents_individual   \n",
              "19       determinants_macro   \n",
              "4   determinants_individual   \n",
              "5   determinants_individual   \n",
              "9       contents_individual   \n",
              "0   determinants_individual   \n",
              "3   determinants_individual   \n",
              "8       contents_individual   \n",
              "20       determinants_macro   \n",
              "1   determinants_individual   \n",
              "2   determinants_individual   \n",
              "7       contents_individual   \n",
              "\n",
              "                                               labels  \\\n",
              "16  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "12  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "23  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "17  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "15  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "13  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "14  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "22  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "11  [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "21  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "18  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "10  [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "6   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "19  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "4   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "5   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "9   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "0   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "3   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "8   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "20  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "1   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "2   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "7   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "\n",
              "                                              ml_algo  accuracy        f1  \\\n",
              "16                     SGDClassifier(random_state=42)  0.500000  0.650602   \n",
              "12                               KNeighborsClassifier  0.476190  0.588235   \n",
              "23        GradientBoostingClassifier(random_state=42)  0.184211  0.444444   \n",
              "17        GradientBoostingClassifier(random_state=42)  0.214286  0.441176   \n",
              "15            RandomForestClassifier(random_state=42)  0.261905  0.405797   \n",
              "13  LogisticRegression(random_state=42, solver='sag')  0.261905  0.393443   \n",
              "14                                                SVC  0.261905  0.393443   \n",
              "22                     SGDClassifier(random_state=42)  0.184211  0.385542   \n",
              "11        GradientBoostingClassifier(random_state=42)  0.186047  0.371429   \n",
              "21            RandomForestClassifier(random_state=42)  0.184211  0.363636   \n",
              "18                               KNeighborsClassifier  0.210526  0.337662   \n",
              "10                     SGDClassifier(random_state=42)  0.186047  0.285714   \n",
              "6                                KNeighborsClassifier  0.116279  0.242424   \n",
              "19  LogisticRegression(random_state=42, solver='sag')  0.078947  0.226415   \n",
              "4                      SGDClassifier(random_state=42)  0.157895  0.181818   \n",
              "5         GradientBoostingClassifier(random_state=42)  0.000000  0.178571   \n",
              "9             RandomForestClassifier(random_state=42)  0.046512  0.142857   \n",
              "0                                KNeighborsClassifier  0.105263  0.133333   \n",
              "3             RandomForestClassifier(random_state=42)  0.078947  0.111111   \n",
              "8                                                 SVC  0.046512  0.109091   \n",
              "20                                                SVC  0.052632  0.081633   \n",
              "1   LogisticRegression(random_state=42, solver='sag')  0.026316  0.043478   \n",
              "2                                                 SVC  0.026316  0.042553   \n",
              "7   LogisticRegression(random_state=42, solver='sag')  0.000000  0.000000   \n",
              "\n",
              "     hamming  \n",
              "16  0.062771  \n",
              "12  0.075758  \n",
              "23  0.210526  \n",
              "17  0.082251  \n",
              "15  0.088745  \n",
              "13  0.080087  \n",
              "14  0.080087  \n",
              "22  0.268421  \n",
              "11  0.037898  \n",
              "21  0.221053  \n",
              "18  0.268421  \n",
              "10  0.051680  \n",
              "6   0.043066  \n",
              "19  0.215789  \n",
              "4   0.078947  \n",
              "5   0.067251  \n",
              "9   0.041344  \n",
              "0   0.076023  \n",
              "3   0.070175  \n",
              "8   0.042205  \n",
              "20  0.236842  \n",
              "1   0.064327  \n",
              "2   0.065789  \n",
              "7   0.044789  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_results_tf.sort_values(\"f1\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_tf.to_csv(\"tf_models.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pickle.dump(model, open(r\"..\\Models\\Contents\\pipeline_contents_One-Many_V4-11-05.sav\", 'wb')) \n",
        "\n",
        "# will save the RF model since it was at the end of the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# pickle.dump(model, open(r\"..\\Models\\Determinants\\pipeline_determinants_One-Many_V4-11-05.sav\", 'wb'))\n",
        "\n",
        "# will save the RF model by default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function to get the predictions back from the tf idf classifier for the individual labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list(y_determinants.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list(y_contents.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the model is tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# def evaluate_one_vs_rest_TFIDF(path, text):\n",
        "    \n",
        "#     pipeline = pickle.load(open(path, \"rb\"))\n",
        "    \n",
        "#     if \"content\" in path:\n",
        "#         # print(\"content found\")\n",
        "#         possible_outcomes = ['(A)', '(Ad)', '(H)', '(Hd)', 'A', 'Abs', 'Ad', 'Alim', 'Anat', 'Art',\n",
        "#        'Bot', 'Elem', 'Frag', 'Ge', 'H', 'Hd', 'Id', 'Nat', 'Obj', 'Pays', 'Radio', 'Sc', 'Sex', 'Sg', 'Vet']\n",
        "        \n",
        "#     elif \"determinant\" in path:\n",
        "#         # print(\"determinant found\")\n",
        "#         possible_outcomes = ['C', 'C\\'', 'C\\'F', 'CF', 'E', 'EF', 'F', 'FC', 'FC\\'', 'FE', 'K', 'kan']\n",
        "\n",
        "#     prediction = pipeline.predict([text])\n",
        "#     probabilities = pipeline.predict_proba([text]) # sometimes no prediction is given back so we can take the outcome with the highest P instead\n",
        "\n",
        "#     # print(\"prediction:\", prediction)\n",
        "#     # print(\"probabilities:\", probabilities)\n",
        "    \n",
        "#     list_predictions = prediction.tolist()\n",
        "#     list_predictions = [x for sublist in list_predictions for x in sublist] # avoid lists with sublists\n",
        "\n",
        "    \n",
        "#     if len(list_predictions) != len(possible_outcomes): # sanity check\n",
        "#         print(prediction)\n",
        "#         print( len(list_predictions)  )\n",
        "#         print(possible_outcomes)\n",
        "#         print( len(possible_outcomes)  )\n",
        "#         print(\"Error encountered in the predictions\")\n",
        "        \n",
        "#     results = ([possible_outcomes[i] for i in range(len(list_predictions)) if list_predictions[i] == 1]) \n",
        "\n",
        "#     if results == []:\n",
        "#         # print(\"No result\")\n",
        "#         i = probabilities.argmax(1).item()\n",
        "#         # print(ix)\n",
        "#         final_results = possible_outcomes[i]\n",
        "    \n",
        "#     else:\n",
        "#         final_results = str(results).replace(\"\\'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "    \n",
        "#     return final_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate_one_vs_rest_TFIDF(r\"..\\Models\\Contents\\pipeline_contents_One-Many_V3-18-04.sav\", \"Dog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate_one_vs_rest_TFIDF(r\"..\\Models\\Determinants\\pipeline_determinants_One-Many_V3-18-04.sav\", \"Dog\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model development with SentenceTransformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text_for_transformer(text):\n",
        "    \n",
        "    embeddings_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    \n",
        "    x_array = embeddings_model.encode(text, convert_to_numpy=True)\n",
        "    \n",
        "    x_centroid = np.mean(x_array)\n",
        "    X_transformers = x_centroid.reshape(-1,1)\n",
        "\n",
        "    \n",
        "    return X_transformers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pre_process_data(df, test_proportion=0.1):\n",
        "\n",
        "    df.columns.values[0] = \"FQText\"\n",
        "    size_df = df.shape[0]\n",
        "    df[\"FQText\"] = df[\"FQText\"].apply(preprocess_text_for_transformer)\n",
        "    X = df[[\"FQText\"]].to_numpy()\n",
        "\n",
        "    y_df = df.drop([\"FQText\"], axis=1).astype(np.float32)\n",
        "    cols = df.columns\n",
        "    df_labels = list(y_df.columns)\n",
        "\n",
        "    y = y_df.to_numpy()\n",
        "\n",
        "    X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size=test_proportion)\n",
        "    \n",
        "    X_train = pd.DataFrame(X_train, columns=[\"FQText\"])\n",
        "    y_train = pd.DataFrame(y_train, columns=[df_labels], dtype=np.float32)\n",
        "    \n",
        "    X_test = pd.DataFrame(X_test, columns=[\"FQText\"])\n",
        "    y_test = pd.DataFrame(y_test, columns=[df_labels], dtype=np.float32)\n",
        "\n",
        "    # print(df_labels)\n",
        "\n",
        "    # print(\"Total amount of data: {}\".format(size_df))\n",
        "    # print(\"Number of rows used to TRAIN: {}\".format(X_train.shape[0]))\n",
        "    # print(\"Number of rows used to TEST: {}\".format(X_test.shape[0]))\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, df_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_sentence_transformers(df_name, models=models):\n",
        "    \n",
        "    name = \"_\".join(df_name.split(\"_\")[1:3])\n",
        "    df = pd.read_csv(df_name)\n",
        "\n",
        "    X_train, y_train, X_test, y_test, df_labels = pre_process_data(df, test_proportion=0.1)\n",
        "    \n",
        "    list_results = []\n",
        "\n",
        "    for model in models:\n",
        "        model_name = str(model).split(\"()\")[0]\n",
        "        dict_model_info = {\"data_model\": name,\n",
        "                            \"labels\": df_labels,\n",
        "                            \"ml_algo\":model_name}\n",
        "        one_v_rest = OneVsRestClassifier(model)\n",
        "\n",
        "        model_fit = one_v_rest.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model_fit.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
        "        hamming = hamming_loss(y_test, y_pred)\n",
        "        \n",
        "        dict_model_info[\"accuracy\"] = accuracy\n",
        "        dict_model_info[\"f1\"] = f1\n",
        "        dict_model_info[\"hamming\"] = hamming\n",
        "        \n",
        "        list_results.append(dict_model_info)\n",
        "    return list_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for df in dfs:\n",
        "    results_per_df = model_sentence_transformers(df)\n",
        "    results.extend(results_per_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results for the Sentence Transformers Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_st = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_model</th>\n",
              "      <th>labels</th>\n",
              "      <th>ml_algo</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>hamming</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.292308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>0.115909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.256410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.346939</td>\n",
              "      <td>0.145455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>0.329114</td>\n",
              "      <td>0.120455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.321839</td>\n",
              "      <td>0.302564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.321839</td>\n",
              "      <td>0.134091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>SVC</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.268657</td>\n",
              "      <td>0.111364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.179487</td>\n",
              "      <td>0.253165</td>\n",
              "      <td>0.302564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.224299</td>\n",
              "      <td>0.073192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.131579</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>0.070175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.119048</td>\n",
              "      <td>0.150538</td>\n",
              "      <td>0.069665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.126316</td>\n",
              "      <td>0.121345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>SVC</td>\n",
              "      <td>0.051282</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.235897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.109649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0.052028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='sag')</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='sag')</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>SVC</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='sag')</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='sag')</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.246154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>SVC</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 data_model  \\\n",
              "21       determinants_macro   \n",
              "16           contents_macro   \n",
              "18       determinants_macro   \n",
              "15           contents_macro   \n",
              "12           contents_macro   \n",
              "22       determinants_macro   \n",
              "17           contents_macro   \n",
              "14           contents_macro   \n",
              "23       determinants_macro   \n",
              "9       contents_individual   \n",
              "0   determinants_individual   \n",
              "11      contents_individual   \n",
              "3   determinants_individual   \n",
              "20       determinants_macro   \n",
              "5   determinants_individual   \n",
              "6       contents_individual   \n",
              "10      contents_individual   \n",
              "1   determinants_individual   \n",
              "13           contents_macro   \n",
              "8       contents_individual   \n",
              "7       contents_individual   \n",
              "4   determinants_individual   \n",
              "19       determinants_macro   \n",
              "2   determinants_individual   \n",
              "\n",
              "                                               labels  \\\n",
              "21  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "16  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "18  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "15  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "12  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "22  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "17  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "14  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "23  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "9   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "0   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "11  [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "3   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "20  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "5   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "6   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "10  [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "1   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "13  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "8   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "7   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "4   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "19  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "2   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "\n",
              "                                              ml_algo  accuracy        f1  \\\n",
              "21            RandomForestClassifier(random_state=42)  0.307692  0.424242   \n",
              "16                     SGDClassifier(random_state=42)  0.375000  0.413793   \n",
              "18                               KNeighborsClassifier  0.256410  0.358974   \n",
              "15            RandomForestClassifier(random_state=42)  0.225000  0.346939   \n",
              "12                               KNeighborsClassifier  0.275000  0.329114   \n",
              "22                     SGDClassifier(random_state=42)  0.205128  0.321839   \n",
              "17        GradientBoostingClassifier(random_state=42)  0.225000  0.321839   \n",
              "14                                                SVC  0.200000  0.268657   \n",
              "23        GradientBoostingClassifier(random_state=42)  0.179487  0.253165   \n",
              "9             RandomForestClassifier(random_state=42)  0.190476  0.224299   \n",
              "0                                KNeighborsClassifier  0.131579  0.172414   \n",
              "11        GradientBoostingClassifier(random_state=42)  0.119048  0.150538   \n",
              "3             RandomForestClassifier(random_state=42)  0.157895  0.126316   \n",
              "20                                                SVC  0.051282  0.080000   \n",
              "5         GradientBoostingClassifier(random_state=42)  0.078947  0.074074   \n",
              "6                                KNeighborsClassifier  0.023810  0.063492   \n",
              "10                     SGDClassifier(random_state=42)  0.000000  0.000000   \n",
              "1   LogisticRegression(random_state=42, solver='sag')  0.000000  0.000000   \n",
              "13  LogisticRegression(random_state=42, solver='sag')  0.000000  0.000000   \n",
              "8                                                 SVC  0.000000  0.000000   \n",
              "7   LogisticRegression(random_state=42, solver='sag')  0.000000  0.000000   \n",
              "4                      SGDClassifier(random_state=42)  0.000000  0.000000   \n",
              "19  LogisticRegression(random_state=42, solver='sag')  0.000000  0.000000   \n",
              "2                                                 SVC  0.000000  0.000000   \n",
              "\n",
              "     hamming  \n",
              "21  0.292308  \n",
              "16  0.115909  \n",
              "18  0.256410  \n",
              "15  0.145455  \n",
              "12  0.120455  \n",
              "22  0.302564  \n",
              "17  0.134091  \n",
              "14  0.111364  \n",
              "23  0.302564  \n",
              "9   0.073192  \n",
              "0   0.070175  \n",
              "11  0.069665  \n",
              "3   0.121345  \n",
              "20  0.235897  \n",
              "5   0.109649  \n",
              "6   0.052028  \n",
              "10  0.045855  \n",
              "1   0.064327  \n",
              "13  0.106818  \n",
              "8   0.045855  \n",
              "7   0.045855  \n",
              "4   0.064327  \n",
              "19  0.246154  \n",
              "2   0.064327  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_results_st.sort_values(\"f1\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_st.to_csv(\"sentence_transformers_models.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to get the label from the Sentence Transformer classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def preprocess_text_for_transformer(text):\n",
        "    \n",
        "#     embeddings_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    \n",
        "#     x_array = embeddings_model.encode(text, convert_to_numpy=True)\n",
        "    \n",
        "#     x_centroid = np.mean(x_array)\n",
        "#     X_transformers = x_centroid.reshape(-1,1)\n",
        "\n",
        "    \n",
        "#     return X_transformers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.0003033], dtype=float32)"
            ]
          },
          "execution_count": 367,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# preprocess_text_for_transformer(\"dog with two tails\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def evaluate_one_vs_rest_transformer(path, text):\n",
        "    \n",
        "#     pipeline = pickle.load(open(path, \"rb\"))\n",
        "    \n",
        "#     if \"content\" in path:\n",
        "#         # print(\"content found\")\n",
        "#         possible_outcomes = ['(A)', '(Ad)', '(H)', '(Hd)', 'A', 'Abs', 'Ad', 'Alim', 'Anat', 'Art',\n",
        "#        'Bot', 'Elem', 'Frag', 'Ge', 'H', 'Hd', 'Id', 'Nat', 'Obj', 'Pays', 'Radio', 'Sc', 'Sex', 'Sg', 'Vet']\n",
        "        \n",
        "#     elif \"determinant\" in path:\n",
        "#         # print(\"determinant found\")\n",
        "#         possible_outcomes = ['C', 'C\\'', 'C\\'F', 'CF', 'E', 'EF', 'F', 'FC', 'FC\\'', 'FE', 'K', 'kan']\n",
        "\n",
        "#     text_transformed = preprocess_text_for_transformer(text)\n",
        "    \n",
        "#     prediction = pipeline.predict([text_transformed])\n",
        "#     probabilities = pipeline.predict_proba([text_transformed]) # sometimes no prediction is given back so we can take the outcome with the highest P instead\n",
        "\n",
        "#     # print(\"prediction:\", prediction)\n",
        "#     # print(\"probabilities:\", probabilities)\n",
        "    \n",
        "#     list_predictions = prediction.tolist()\n",
        "#     list_predictions = [x for sublist in list_predictions for x in sublist] # avoid lists with sublists\n",
        "\n",
        "    \n",
        "#     if len(list_predictions) != len(possible_outcomes): # sanity check\n",
        "#         print(prediction)\n",
        "#         print( len(list_predictions)  )\n",
        "#         print(possible_outcomes)\n",
        "#         print( len(possible_outcomes)  )\n",
        "#         print(\"Error encountered in the predictions\")\n",
        "        \n",
        "#     results = ([possible_outcomes[i] for i in range(len(list_predictions)) if list_predictions[i] == 1]) \n",
        "\n",
        "#     if results == []:\n",
        "#         # print(\"No result\")\n",
        "#         i = probabilities.argmax(1).item()\n",
        "#         # print(ix)\n",
        "#         final_results = possible_outcomes[i]\n",
        "    \n",
        "#     else:\n",
        "#         final_results = str(results).replace(\"\\'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "    \n",
        "#     return final_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.00023756], dtype=float32)"
            ]
          },
          "execution_count": 369,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# preprocess_text_for_transformer(\"dog with tail\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A, Anat'"
            ]
          },
          "execution_count": 370,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate_one_vs_rest_transformer(r\"..\\Models\\Contents\\sentence_transformer_contents_V23-18-04.sav\", \"Dog with tail\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'F, FE'"
            ]
          },
          "execution_count": 371,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate_one_vs_rest_transformer(r\"..\\Models\\Determinants\\sentence_transformer_determinants_V23-18-04.sav\", \"Dog with tail\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
