{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-GV8nLI2AXD",
        "outputId": "33d03cfa-d5a5-4f18-b0e4-b26b60378e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BRCz44s2_5s",
        "outputId": "52b90575-ad78-4dcc-ea38-e19ccf3f8e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "cpNn76Ej2b7Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig, BertModel\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics.cluster import contingency_matrix\n",
        "\n",
        "import shutil\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NAEtmzK-AIRj"
      },
      "outputs": [],
      "source": [
        "def pre_process_data(df, test_proportion, train_size):\n",
        "\n",
        "    size_df = df.shape[0]\n",
        "    df = shuffle(df)\n",
        "    X = df[[\"FQText\"]]\n",
        "    y = df.drop([\"FQText\"], axis=1)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_proportion, shuffle=True, random_state=42)\n",
        "\n",
        "    df_train = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\n",
        "    df_test = pd.concat([X_test, y_test], axis=1).reset_index(drop=True)\n",
        "    df_labels = list(y.columns)\n",
        "\n",
        "    print(df_labels)\n",
        "\n",
        "    train_df = df_train.sample(frac=train_size, random_state=42).reset_index(drop=True)\n",
        "    val_df = df_train.drop(train_df.index).reset_index(drop=True)\n",
        "\n",
        "    print(\"Total amount of data: {}\".format(size_df))\n",
        "    print(\"Number of rows used to TRAIN: {}\".format(train_df.shape[0]))\n",
        "    print(\"Number of rows used to VALIDATE: {}\".format(val_df.shape[0]))\n",
        "    print(\"Number of rows used to TEST: {}\".format(df_test.shape[0]))\n",
        "\n",
        "    return train_df, val_df, df_test, df_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "020inJJS15jg"
      },
      "outputs": [],
      "source": [
        "def set_hyperparams(hp_dictionary):\n",
        "\n",
        "    MAX_LEN = hp_dictionary[\"MAX_LEN\"]\n",
        "    TRAIN_BATCH_SIZE = hp_dictionary[\"TRAIN_BATCH_SIZE\"]\n",
        "    VALID_BATCH_SIZE = hp_dictionary[\"VALID_BATCH_SIZE\"]\n",
        "    EPOCHS = hp_dictionary[\"EPOCHS\"]\n",
        "    LEARNING_RATE = hp_dictionary[\"LEARNING_RATE\"]\n",
        "\n",
        "    return MAX_LEN, TRAIN_BATCH_SIZE, VALID_BATCH_SIZE, EPOCHS, LEARNING_RATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MFhEjXxU15jg"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into\n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # return model, optimizer, epoch value, min validation loss\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n",
        "\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "By6QjBoA15jh"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.title = df['FQText']\n",
        "        # self.labels = list(df.columns)[2:] # list of the target values\n",
        "        self.targets = self.df[df_labels].values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True, # do we actually need special tokens ??\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'  # pytorch tensors\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
        "            'targets': torch.FloatTensor(self.targets[index])\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JfND4miy15jh"
      },
      "outputs": [],
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.linear = torch.nn.Linear(768, len(df_labels)) # have to changet he n of possible labels here\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
        "        output = self.bert_model(\n",
        "            input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        # the issue is that bert gets size 6 here?\n",
        "        output_dropout = self.dropout(output.pooler_output)\n",
        "        # print(output_dropout)\n",
        "        output = self.linear(output_dropout)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rD0OObyw15jh"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    # print(outputs, targets)\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "1inxJZtT15jh"
      },
      "outputs": [],
      "source": [
        "def train_model(n_epochs, training_loader, validation_loader, model,\n",
        "                optimizer, checkpoint_path, best_model_path):\n",
        "  # initialize tracker for minimum validation loss\n",
        "  valid_loss_min = np.Inf\n",
        "\n",
        "\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    print('############# Epoch {}: Training Start   #############'.format(epoch))\n",
        "    for batch_idx, data in enumerate(training_loader):\n",
        "        # print('yyy epoch', batch_idx)\n",
        "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        \"\"\"targets are the y array of the original data.\n",
        "        \"\"\"\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print('before loss data in training', loss.item(), train_loss)\n",
        "        train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
        "        #print('after loss data in training', loss.item(), train_loss)\n",
        "\n",
        "\n",
        "\n",
        "    print('############# Epoch {}: Training End     #############'.format(epoch))\n",
        "\n",
        "    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n",
        "    ######################\n",
        "    # validate the model #\n",
        "    ######################\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    metrics_targets = []\n",
        "    metrics_outputs = []\n",
        "    softm = torch.nn.Softmax(dim=1) # needed to get the actual predictions\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, data in enumerate(validation_loader, 0):\n",
        "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
        "            val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "\n",
        "            outputs = model(ids.squeeze(), mask.squeeze(), token_type_ids.squeeze())\n",
        "\n",
        "            metrics_targets.extend(torch.argmax(softm(targets), dim=1).cpu().detach().numpy().tolist())\n",
        "            metrics_outputs.extend(torch.argmax(softm(outputs), dim=1).cpu().detach().numpy().tolist())\n",
        "\n",
        "      metrics_outputs = np.array(metrics_outputs, dtype=int)\n",
        "      val_f1 = f1_score(metrics_outputs, metrics_targets, average=\"weighted\")\n",
        "      val_acc = accuracy_score(metrics_outputs, metrics_targets)\n",
        "      class_report = classification_report(metrics_outputs, metrics_targets)\n",
        "\n",
        "      print((f\"Accuracy: {val_f1}\"))\n",
        "      print((f\"F1 Score (Weighted): {val_f1}\"))\n",
        "      print((f\"Classification report: \\n{class_report}\"))\n",
        "\n",
        "\n",
        "\n",
        "      print('############# Epoch {}: Validation End     #############'.format(epoch))\n",
        "\n",
        "      # calculate average losses\n",
        "      #print('before cal avg train loss', train_loss)\n",
        "      train_loss = train_loss/len(training_loader)\n",
        "      valid_loss = valid_loss/len(validation_loader)\n",
        "      # print training/validation statistics\n",
        "      print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "\n",
        "      # create checkpoint variable and add important data\n",
        "      checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': valid_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "      }\n",
        "\n",
        "        # save checkpoint\n",
        "      save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "\n",
        "      ## TODO: save the model if validation loss has decreased\n",
        "      if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "        # save checkpoint as best model\n",
        "        save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "    print('############# Epoch {}  Done   #############\\n'.format(epoch))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not used at the moment\n",
        "\n",
        "# def compute_metrics(epoch, validation_loader):\n",
        "#   model.eval()\n",
        "#   metrics_targets = []\n",
        "#   metrics_outputs = []\n",
        "#   softm = torch.nn.Softmax(dim=1)\n",
        "#   with torch.no_grad():\n",
        "#         for _, data in enumerate(validation_loader, 0):\n",
        "#               ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "#               mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "#               token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "#               targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "#               outputs = model(ids.squeeze(), mask.squeeze(), token_type_ids.squeeze())\n",
        "\n",
        "#               metrics_targets.extend(torch.argmax(softm(targets), dim=1).cpu().detach().numpy().tolist())\n",
        "#               metrics_outputs.extend(torch.argmax(softm(outputs), dim=1).cpu().detach().numpy().tolist())\n",
        "\n",
        "#   return metrics_targets, metrics_outputs"
      ],
      "metadata": {
        "id": "3C3Cl8UnqkrC"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_test_metrics(test_loader):\n",
        "  model.eval()\n",
        "  metrics_targets = []\n",
        "  metrics_outputs = []\n",
        "  softm = torch.nn.Softmax(dim=1)\n",
        "  with torch.no_grad():\n",
        "        for _, data in enumerate(test_loader, 0):\n",
        "              ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "              mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "              token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "              targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "              outputs = model(ids.squeeze(), mask.squeeze(), token_type_ids.squeeze())\n",
        "\n",
        "              metrics_targets.extend(torch.argmax(softm(targets), dim=1).cpu().detach().numpy().tolist())\n",
        "              metrics_outputs.extend(torch.argmax(softm(outputs), dim=1).cpu().detach().numpy().tolist())\n",
        "\n",
        "  return metrics_targets, metrics_outputs"
      ],
      "metadata": {
        "id": "-LLrqlZuvVRR"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN AND VALIDATION LOOP"
      ],
      "metadata": {
        "id": "K-rvtFb1ByjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determinants"
      ],
      "metadata": {
        "id": "utSjW4nUBudm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"nancy_determinants_grouped.csv\")\n"
      ],
      "metadata": {
        "id": "YO1ZAHm2pH0Q"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GROUPED"
      ],
      "metadata": {
        "id": "q1QmCorGB56k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns = {\"Answer (English)\": \"FQText\"}, inplace=True)\n",
        "\n",
        "df.drop(['Déterminant', 'C', 'C\\'', 'C\\'F',\n",
        "       'CF', 'CF\\'', 'CLOB', 'CLOBF', 'E', 'EF', 'F', 'FC', 'FC\\'', 'FCLOB',\n",
        "       'FE', 'K', 'KAN', 'KOB', 'KP', 'Réponse (French)'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "3k2rFrs5B3eL"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwsqVD3wpIQ1",
        "outputId": "e5516e00-bdff-4a22-b639-0c8038b2c926"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['FQText', 'color_sum', 'threat_sum', 'fading_sum', 'form_sum',\n",
              "       'kinesthetics_sum'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDIVIDUAL"
      ],
      "metadata": {
        "id": "2d7u4ywFCRJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns = {\"Answer (English)\": \"FQText\"}, inplace=True)\n",
        "\n",
        "df.drop(['Déterminant', 'color_sum', 'threat_sum', 'fading_sum',\n",
        "       'form_sum', 'kinesthetics_sum', 'Réponse (French)'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "9BV42umwB_A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "8jWuAeE8CGVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contents"
      ],
      "metadata": {
        "id": "nsrPLGg4CIyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"nancy_contents_grouped.csv\")\n"
      ],
      "metadata": {
        "id": "cbDvsEuK43vS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GROUPED"
      ],
      "metadata": {
        "id": "Ebg_fC5uBy5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns = {\"Answer (English)\": \"FQText\"}, inplace=True)\n",
        "\n",
        "df.drop(['Contenu', '(A)', '(AD)', '(H)', '(HD)',\n",
        "       'A', 'ABS', 'AD', 'ALIM', 'ANAT', 'ARCH', 'ART', 'BOT', 'ELEM', 'FRAG',\n",
        "       'GÉO', 'H', 'HD', 'MQ', 'NAT', 'OBJ', 'PAYS', 'RADIO', 'SC', 'SCÈNE',\n",
        "       'SEX', 'SG', 'VÊT', 'Réponse (French)'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "H85aZstXCVRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJkQypP1Aghv",
        "outputId": "dac343bb-360c-4e0f-9139-4f983ebd30c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['FQText', 'animal_sum', 'human_sum', 'abs_sum', 'food_sum',\n",
              "       'art_arch_sum', 'nature_sum', 'fragment_sum', 'geo_sum', 'object_sum',\n",
              "       'science_sum', 'graphic_sum'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDIVIDUAL"
      ],
      "metadata": {
        "id": "XIghMIOuCSZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns = {\"Answer (English)\": \"FQText\"}, inplace=True)\n",
        "\n",
        "df.drop(['Contenu', 'animal_sum', 'human_sum', 'abs_sum',\n",
        "       'food_sum', 'art_arch_sum', 'nature_sum', 'fragment_sum', 'geo_sum',\n",
        "       'object_sum', 'science_sum', 'graphic_sum', 'Réponse (French)'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "-vKjiDTBCZG-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqSzXgVtClTR",
        "outputId": "6b2ef529-ebd9-4540-efa1-0ebd56e61a2e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['FQText', '(A)', '(AD)', '(H)', '(HD)', 'A', 'ABS', 'AD', 'ALIM',\n",
              "       'ANAT', 'ARCH', 'ART', 'BOT', 'ELEM', 'FRAG', 'GÉO', 'H', 'HD', 'MQ',\n",
              "       'NAT', 'OBJ', 'PAYS', 'RADIO', 'SC', 'SCÈNE', 'SEX', 'SG', 'VÊT'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "fDCIfjfOCtCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp_dictionary = {\"MAX_LEN\":256 ,\n",
        "    \"TRAIN_BATCH_SIZE\": 16,\n",
        "    \"VALID_BATCH_SIZE\": 16,\n",
        "    \"EPOCHS\": 4,\n",
        "    \"LEARNING_RATE\": 1e-05\n",
        "}"
      ],
      "metadata": {
        "id": "HOx4W-iAplm2"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thCkEarT_sEz",
        "outputId": "c2361eb4-fbcc-4a1c-ac51-ef01e8f6f87d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "I-BxMEEb15jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37da92ec-5da1-4d14-e9a0-66680967fa4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['color_sum', 'threat_sum', 'fading_sum', 'form_sum', 'kinesthetics_sum']\n",
            "Total amount of data: 380\n",
            "Number of rows used to TRAIN: 325\n",
            "Number of rows used to VALIDATE: 36\n",
            "Number of rows used to TEST: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN, TRAIN_BATCH_SIZE, VALID_BATCH_SIZE, EPOCHS, LEARNING_RATE = set_hyperparams(hp_dictionary)\n",
        "\n",
        "test_proportion = 0.05\n",
        "test_size = 0.9\n",
        "\n",
        "train_df, val_df, df_test, df_labels  = pre_process_data(df, test_proportion, test_size)\n",
        "\n",
        "\n",
        "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
        "valid_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "proba_threshold = 0.5\n",
        "val_targets=[]\n",
        "val_outputs=[]\n",
        "\n",
        "ckpt_path = \"curr_ckpt\"\n",
        "best_model_path = \"best_model.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFeKHNTX15ji",
        "outputId": "0a6cbee7-0121-4a8f-aeda-155690550746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Epoch 1: Training Start   #############\n",
            "############# Epoch 1: Training End     #############\n",
            "############# Epoch 1: Validation Start   #############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.466286799620133\n",
            "F1 Score (Weighted): 0.466286799620133\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.60      0.30         5\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.85      0.48      0.61        23\n",
            "           4       0.20      0.12      0.15         8\n",
            "\n",
            "    accuracy                           0.42        36\n",
            "   macro avg       0.25      0.24      0.21        36\n",
            "weighted avg       0.61      0.42      0.47        36\n",
            "\n",
            "############# Epoch 1: Validation End     #############\n",
            "Epoch: 1 \tAvgerage Training Loss: 0.027545 \tAverage Validation Loss: 0.185199\n",
            "Validation loss decreased (inf --> 0.185199).  Saving model ...\n",
            "############# Epoch 1  Done   #############\n",
            "\n",
            "############# Epoch 2: Training Start   #############\n",
            "############# Epoch 2: Training End     #############\n",
            "############# Epoch 2: Validation Start   #############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5385802469135802\n",
            "F1 Score (Weighted): 0.5385802469135802\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.52      0.61        21\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.46      0.43      0.44        14\n",
            "           4       0.20      1.00      0.33         1\n",
            "\n",
            "    accuracy                           0.50        36\n",
            "   macro avg       0.28      0.39      0.28        36\n",
            "weighted avg       0.61      0.50      0.54        36\n",
            "\n",
            "############# Epoch 2: Validation End     #############\n",
            "Epoch: 2 \tAvgerage Training Loss: 0.025147 \tAverage Validation Loss: 0.175182\n",
            "Validation loss decreased (0.185199 --> 0.175182).  Saving model ...\n",
            "############# Epoch 2  Done   #############\n",
            "\n",
            "############# Epoch 3: Training Start   #############\n",
            "############# Epoch 3: Training End     #############\n",
            "############# Epoch 3: Validation Start   #############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5723223223223222\n",
            "F1 Score (Weighted): 0.5723223223223222\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.55      0.65        22\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.46      0.46      0.46        13\n",
            "           4       0.20      1.00      0.33         1\n",
            "\n",
            "    accuracy                           0.53        36\n",
            "   macro avg       0.29      0.40      0.29        36\n",
            "weighted avg       0.66      0.53      0.57        36\n",
            "\n",
            "############# Epoch 3: Validation End     #############\n",
            "Epoch: 3 \tAvgerage Training Loss: 0.024294 \tAverage Validation Loss: 0.172149\n",
            "Validation loss decreased (0.175182 --> 0.172149).  Saving model ...\n",
            "############# Epoch 3  Done   #############\n",
            "\n",
            "############# Epoch 4: Training Start   #############\n",
            "############# Epoch 4: Training End     #############\n",
            "############# Epoch 4: Validation Start   #############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5954715219421103\n",
            "F1 Score (Weighted): 0.5954715219421103\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.58      0.65        19\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.62      0.53      0.57        15\n",
            "           4       0.20      0.50      0.29         2\n",
            "\n",
            "    accuracy                           0.56        36\n",
            "   macro avg       0.31      0.32      0.30        36\n",
            "weighted avg       0.65      0.56      0.60        36\n",
            "\n",
            "############# Epoch 4: Validation End     #############\n",
            "Epoch: 4 \tAvgerage Training Loss: 0.023690 \tAverage Validation Loss: 0.166850\n",
            "Validation loss decreased (0.172149 --> 0.166850).  Saving model ...\n",
            "############# Epoch 4  Done   #############\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, ckpt_path, best_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST"
      ],
      "metadata": {
        "id": "BFJgtECyBvt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "ti3K0jiLBox7"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_targets, metrics_outputs =  compute_test_metrics(test_data_loader)\n",
        "\n",
        "metrics_outputs = np.array(metrics_outputs, dtype=int)\n",
        "\n",
        "val_f1 = f1_score(metrics_outputs, metrics_targets, average=\"weighted\")\n",
        "val_acc = accuracy_score(metrics_outputs, metrics_targets)\n",
        "class_report = classification_report(metrics_outputs, metrics_targets)\n",
        "print((f\"Accuracy: {val_f1}\"))\n",
        "print((f\"F1 Score (Weighted): {val_f1}\"))\n",
        "print((f\"Classification report: \\n{class_report}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWePtx-juAM7",
        "outputId": "96d91ab5-95dc-41e5-d478-5cf648f69941"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.593440122044241\n",
            "F1 Score (Weighted): 0.593440122044241\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.33      0.44         6\n",
            "           1       0.00      0.00      0.00         0\n",
            "           3       0.75      0.82      0.78        11\n",
            "           4       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.58        19\n",
            "   macro avg       0.35      0.29      0.31        19\n",
            "weighted avg       0.64      0.58      0.59        19\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}