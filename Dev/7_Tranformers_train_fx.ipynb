{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-GV8nLI2AXD",
        "outputId": "87d1c9fd-5599-499f-c8a1-b0ecafd25cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BRCz44s2_5s",
        "outputId": "0f2217d7-8867-4893-fb3b-00a683833db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cpNn76Ej2b7Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig, BertModel\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics.cluster import contingency_matrix\n",
        "\n",
        "import shutil\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NAEtmzK-AIRj"
      },
      "outputs": [],
      "source": [
        "def pre_process_data(df, test_proportion, train_size):\n",
        "\n",
        "    size_df = df.shape[0]\n",
        "    df = shuffle(df, random_state = 42)\n",
        "    X = df[[\"FQText\"]]\n",
        "    y = df.drop([\"FQText\"], axis=1).astype(np.float32)\n",
        "    print(y.info())\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_proportion, shuffle=True, random_state=42)\n",
        "\n",
        "    df_train = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\n",
        "    df_test = pd.concat([X_test, y_test], axis=1).reset_index(drop=True)\n",
        "    df_labels = list(y.columns)\n",
        "\n",
        "    print(df_labels)\n",
        "\n",
        "    train_df = df_train.sample(frac=train_size, random_state=42).reset_index(drop=True)\n",
        "    val_df = df_train.drop(train_df.index).reset_index(drop=True)\n",
        "\n",
        "    print(\"Total amount of data: {}\".format(size_df))\n",
        "    print(\"Number of rows used to TRAIN: {}\".format(train_df.shape[0]))\n",
        "    print(\"Number of rows used to VALIDATE: {}\".format(val_df.shape[0]))\n",
        "    print(\"Number of rows used to TEST: {}\".format(df_test.shape[0]))\n",
        "\n",
        "    return train_df, val_df, df_test, df_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "020inJJS15jg"
      },
      "outputs": [],
      "source": [
        "def set_hyperparams(hp_dictionary):\n",
        "\n",
        "    MAX_LEN = hp_dictionary[\"MAX_LEN\"]\n",
        "    TRAIN_BATCH_SIZE = hp_dictionary[\"TRAIN_BATCH_SIZE\"]\n",
        "    VALID_BATCH_SIZE = hp_dictionary[\"VALID_BATCH_SIZE\"]\n",
        "    EPOCHS = hp_dictionary[\"EPOCHS\"]\n",
        "    LEARNING_RATE = hp_dictionary[\"LEARNING_RATE\"]\n",
        "\n",
        "    return MAX_LEN, TRAIN_BATCH_SIZE, VALID_BATCH_SIZE, EPOCHS, LEARNING_RATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "MFhEjXxU15jg"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into\n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # return model, optimizer, epoch value, min validation loss\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n",
        "\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "By6QjBoA15jh"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.title = df['FQText']\n",
        "        # self.labels = list(df.columns)[2:] # list of the target values\n",
        "        self.targets = self.df[df_labels].values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True, # do we actually need special tokens ??\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'  # pytorch tensors\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
        "            'targets': torch.FloatTensor(self.targets[index])\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CAMBIAR EL PROBLEM TYPE AQUÍ"
      ],
      "metadata": {
        "id": "_9GEKc0WjDV5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "JfND4miy15jh"
      },
      "outputs": [],
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True, problem_type=\"multi_label_classification\")\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.linear = torch.nn.Linear(768, len(df_labels)) # have to changet he n of possible labels here\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
        "        output = self.bert_model(\n",
        "            input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        # the issue is that bert gets size 6 here?\n",
        "        output_dropout = self.dropout(output.pooler_output)\n",
        "        # print(output_dropout)\n",
        "        output = self.linear(output_dropout)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "rD0OObyw15jh"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    # print(outputs, targets)\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "1inxJZtT15jh"
      },
      "outputs": [],
      "source": [
        "def train_model(n_epochs, training_loader, validation_loader, model,\n",
        "                optimizer, checkpoint_path, best_model_path, df_labels):\n",
        "  # initialize tracker for minimum validation loss\n",
        "  valid_loss_min = np.Inf\n",
        "\n",
        "\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    print('############# Epoch {}: Training Start   #############'.format(epoch))\n",
        "    for batch_idx, data in enumerate(training_loader):\n",
        "        # print('yyy epoch', batch_idx)\n",
        "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        \"\"\"targets are the y array of the original data.\n",
        "        \"\"\"\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print('before loss data in training', loss.item(), train_loss)\n",
        "        train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
        "        #print('after loss data in training', loss.item(), train_loss)\n",
        "\n",
        "\n",
        "\n",
        "    print('############# Epoch {}: Training End     #############'.format(epoch))\n",
        "\n",
        "    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n",
        "    ######################\n",
        "    # validate the model #\n",
        "    ######################\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    val_targets = []\n",
        "    val_outputs = []\n",
        "    softm = torch.nn.Softmax(dim=1) # needed to get the actual predictions\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, data in enumerate(validation_loader, 0):\n",
        "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
        "        val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "        val_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
        "\n",
        "\n",
        "        # outputs = model(ids.squeeze(), mask.squeeze(), token_type_ids.squeeze())\n",
        "\n",
        "\n",
        "\n",
        "      #       metrics_targets.extend(torch.argmax(softm(targets), dim=1).cpu().detach().numpy().tolist())\n",
        "      #       metrics_outputs.extend(torch.argmax(softm(outputs), dim=1).cpu().detach().numpy().tolist())\n",
        "\n",
        "      # metrics_outputs = np.array(metrics_outputs, dtype=int)\n",
        "      # val_f1 = f1_score(metrics_outputs, metrics_targets, average=\"weighted\")\n",
        "      # val_acc = accuracy_score(metrics_outputs, metrics_targets)\n",
        "      # class_report = classification_report(metrics_outputs, metrics_targets, target_names = df_labels)\n",
        "\n",
        "      # print((f\"Accuracy: {val_f1}\"))\n",
        "      # print((f\"F1 Score (Weighted): {val_f1}\"))\n",
        "      # print((f\"Classification report: \\n{class_report}\"))\n",
        "\n",
        "\n",
        "\n",
        "      print('############# Epoch {}: Validation End     #############'.format(epoch))\n",
        "\n",
        "      # calculate average losses\n",
        "      #print('before cal avg train loss', train_loss)\n",
        "      train_loss = train_loss/len(training_loader)\n",
        "      valid_loss = valid_loss/len(validation_loader)\n",
        "      # print training/validation statistics\n",
        "      print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "\n",
        "      # create checkpoint variable and add important data\n",
        "      checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': valid_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "      }\n",
        "\n",
        "        # save checkpoint\n",
        "      save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "\n",
        "      ## TODO: save the model if validation loss has decreased\n",
        "      # if valid_loss <= valid_loss_min:\n",
        "      #   print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "      #   # save checkpoint as best model\n",
        "      #   save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "      #   valid_loss_min = valid_loss\n",
        "\n",
        "\n",
        "\n",
        "    print('############# Epoch {}  Metrics   #############\\n\\n'.format(epoch))\n",
        "    metrics = multi_labels_metrics(val_outputs, val_targets)\n",
        "    # print((f\"EVAL METRICS: {metrics}\\n\"))\n",
        "\n",
        "    print('############# Epoch {}  Done   #############\\n'.format(epoch))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FuJfhnbd8gU4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9OJEqgab09XX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# not used at the moment\n",
        "\n",
        "# def compute_metrics(epoch, validation_loader):\n",
        "#   model.eval()\n",
        "#   metrics_targets = []\n",
        "#   metrics_outputs = []\n",
        "#   softm = torch.nn.Softmax(dim=1)\n",
        "#   with torch.no_grad():\n",
        "#         for _, data in enumerate(validation_loader, 0):\n",
        "#               ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "#               mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "#               token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "#               targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "#               outputs = model(ids.squeeze(), mask.squeeze(), token_type_ids.squeeze())\n",
        "\n",
        "#               metrics_targets.extend(torch.argmax(softm(targets), dim=1).cpu().detach().numpy().tolist())\n",
        "#               metrics_outputs.extend(torch.argmax(softm(outputs), dim=1).cpu().detach().numpy().tolist())\n",
        "\n",
        "#   return metrics_targets, metrics_outputs"
      ],
      "metadata": {
        "id": "3C3Cl8UnqkrC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-LLrqlZuvVRR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN AND VALIDATION LOOP"
      ],
      "metadata": {
        "id": "K-rvtFb1ByjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determinants"
      ],
      "metadata": {
        "id": "utSjW4nUBudm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"nancy_determinants_grouped.csv\")\n"
      ],
      "metadata": {
        "id": "YO1ZAHm2pH0Q"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GROUPED"
      ],
      "metadata": {
        "id": "q1QmCorGB56k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns = {\"Answer (English)\": \"FQText\"}, inplace=True)\n",
        "\n",
        "df.drop(['Déterminant', 'C', 'C\\'', 'C\\'F',\n",
        "       'CF', 'CF\\'', 'CLOB', 'CLOBF', 'E', 'EF', 'F', 'FC', 'FC\\'', 'FCLOB',\n",
        "       'FE', 'K', 'KAN', 'KOB', 'KP', 'Réponse (French)'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "3k2rFrs5B3eL"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.columns"
      ],
      "metadata": {
        "id": "NwsqVD3wpIQ1"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDIVIDUAL"
      ],
      "metadata": {
        "id": "2d7u4ywFCRJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df.rename(columns = {\"Answer (English)\": \"FQText\"}, inplace=True)\n",
        "\n",
        "# df.drop(['Déterminant', 'color_sum', 'threat_sum', 'fading_sum',\n",
        "#        'form_sum', 'kinesthetics_sum', 'Réponse (French)'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "9BV42umwB_A6"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.columns"
      ],
      "metadata": {
        "id": "8jWuAeE8CGVT"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contents"
      ],
      "metadata": {
        "id": "nsrPLGg4CIyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(\"nancy_contents_grouped.csv\")\n"
      ],
      "metadata": {
        "id": "cbDvsEuK43vS"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GROUPED"
      ],
      "metadata": {
        "id": "Ebg_fC5uBy5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df.rename(columns = {\"Answer (English)\": \"FQText\"}, inplace=True)\n",
        "\n",
        "# df.drop(['Contenu', '(A)', '(AD)', '(H)', '(HD)',\n",
        "#        'A', 'ABS', 'AD', 'ALIM', 'ANAT', 'ARCH', 'ART', 'BOT', 'ELEM', 'FRAG',\n",
        "#        'GÉO', 'H', 'HD', 'MQ', 'NAT', 'OBJ', 'PAYS', 'RADIO', 'SC', 'SCÈNE',\n",
        "#        'SEX', 'SG', 'VÊT', 'Réponse (French)'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "H85aZstXCVRA"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.columns"
      ],
      "metadata": {
        "id": "nJkQypP1Aghv"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDIVIDUAL"
      ],
      "metadata": {
        "id": "XIghMIOuCSZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df.rename(columns = {\"Answer (English)\": \"FQText\"}, inplace=True)\n",
        "\n",
        "# df.drop(['Contenu', 'animal_sum', 'human_sum', 'abs_sum',\n",
        "#        'food_sum', 'art_arch_sum', 'nature_sum', 'fragment_sum', 'geo_sum',\n",
        "#        'object_sum', 'science_sum', 'graphic_sum', 'Réponse (French)'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "-vKjiDTBCZG-"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.columns"
      ],
      "metadata": {
        "id": "rqSzXgVtClTR"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "fDCIfjfOCtCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp_dictionary = {\"MAX_LEN\":256 ,\n",
        "    \"TRAIN_BATCH_SIZE\": 16,\n",
        "    \"VALID_BATCH_SIZE\": 16,\n",
        "    \"EPOCHS\": 4,\n",
        "    \"LEARNING_RATE\": 1e-05\n",
        "}"
      ],
      "metadata": {
        "id": "HOx4W-iAplm2"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHANGE PROBLEM TYPE AQUI"
      ],
      "metadata": {
        "id": "o3Jrv-cgjdnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', problem_type=\"multi_label_classification\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thCkEarT_sEz",
        "outputId": "e3ad2da1-ad00-4a4f-bb9c-62dd1a26ee55"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHANGE PROBLEM TYPE AQUI?"
      ],
      "metadata": {
        "id": "2bu3IYa7jqUu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "I-BxMEEb15jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da986cb-b1e1-4b4e-9d23-e871d9484566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 380 entries, 266 to 102\n",
            "Data columns (total 5 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   color_sum         380 non-null    float32\n",
            " 1   threat_sum        380 non-null    float32\n",
            " 2   fading_sum        380 non-null    float32\n",
            " 3   form_sum          380 non-null    float32\n",
            " 4   kinesthetics_sum  380 non-null    float32\n",
            "dtypes: float32(5)\n",
            "memory usage: 10.4 KB\n",
            "None\n",
            "['color_sum', 'threat_sum', 'fading_sum', 'form_sum', 'kinesthetics_sum']\n",
            "Total amount of data: 380\n",
            "Number of rows used to TRAIN: 291\n",
            "Number of rows used to VALIDATE: 51\n",
            "Number of rows used to TEST: 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN, TRAIN_BATCH_SIZE, VALID_BATCH_SIZE, EPOCHS, LEARNING_RATE = set_hyperparams(hp_dictionary)\n",
        "\n",
        "test_proportion = 0.1\n",
        "test_size = 0.85\n",
        "\n",
        "train_df, val_df, df_test, df_labels  = pre_process_data(df, test_proportion, test_size)\n",
        "\n",
        "\n",
        "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
        "valid_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "proba_threshold = 0.5\n",
        "\n",
        "\n",
        "ckpt_path = \"curr_ckpt\"\n",
        "best_model_path = \"best_model.pt\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counting the labels present in each train/test/val batch\n"
      ],
      "metadata": {
        "id": "1J9n1jlpXfQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def count_instances(y):\n",
        "#   total_labels = 0\n",
        "#   for col in y:\n",
        "#       if col == \"FQText\":\n",
        "#           continue\n",
        "#       else:\n",
        "#           sum_examples = y[col].sum()\n",
        "#           print(col, sum_examples)"
      ],
      "metadata": {
        "id": "dlmtE6LEWSIi"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_val = val_df.drop(\"FQText\", axis=1)\n",
        "# y_train = train_df.drop(\"FQText\", axis=1)\n",
        "# y_test = df_test.drop(\"FQText\", axis=1)\n"
      ],
      "metadata": {
        "id": "uDeEu92CWXhp"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"train class distribution\".upper())\n",
        "# print(\"\")\n",
        "# print(count_instances(y_train))\n",
        "# print(\"total size of the test data\", len(y_train))\n",
        "# print(\"\\nvalidation class distribution\".upper())\n",
        "# print(\"\")\n",
        "# print(count_instances(y_val))\n",
        "# print(\"total size of the test data\", len(y_val))\n",
        "# print(\"\\ntest class distribution\".upper())\n",
        "# print(\"\")\n",
        "# print(count_instances(y_test))\n",
        "# print(\"total size of the test data\", len(y_test))"
      ],
      "metadata": {
        "id": "OzlseIbCW20h"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://discuss.huggingface.co/t/dataset-label-format-for-multi-label-text-classification/14998\n",
        "\n",
        "\n",
        "https://colab.research.google.com/drive/1aue7x525rKy6yYLqqt-5Ll96qjQvpqS7#scrollTo=6d869uZsT9MH\n",
        "\n",
        "https://discuss.huggingface.co/t/multi-class-using-dataset/8970/3\n",
        "\n",
        "https://www.youtube.com/watch?v=ZYc9za75Chk"
      ],
      "metadata": {
        "id": "xNKen3HtcgrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, f1_score, hamming_loss\n",
        "from transformers import EvalPrediction\n",
        "import torch\n",
        "\n",
        "\n",
        "def multi_labels_metrics(predictions, targets, threshold=0.355, df_labels=df_labels): # mess with threshold\n",
        "  sigmoid = torch.nn.Sigmoid()\n",
        "  probs = sigmoid(torch.Tensor(predictions)) #mapply activation function in the raw values\n",
        "\n",
        "  y_pred = np.zeros(probs.shape)\n",
        "  y_pred[np.where(probs>=threshold)] = 1\n",
        "  y_true = targets\n",
        "\n",
        "  f1 = f1_score(y_true, y_pred, average = 'micro')\n",
        "  roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "  hamming = hamming_loss(y_true, y_pred)\n",
        "  class_report = classification_report(y_true, y_pred, target_names=df_labels)\n",
        "\n",
        "  metrics = {\n",
        "      \"roc_auc\": roc_auc,       # special multilabel metrics\n",
        "      \"hamming_loss\": hamming,  # special multilabel metrics\n",
        "      \"f1\": f1\n",
        "  }\n",
        "  print(metrics)\n",
        "  print(class_report)\n",
        "  return metrics\n",
        "\n",
        "def compute_test_metrics(test_loader):\n",
        "\n",
        "  model.eval()\n",
        "  metrics_targets = []\n",
        "  metrics_outputs = []\n",
        "  # softm = torch.nn.Softmax(dim=1)\n",
        "  with torch.no_grad():\n",
        "        for _, data in enumerate(test_loader, 0):\n",
        "              ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "              mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "              token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "              targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "              outputs = model(ids.squeeze(), mask.squeeze(), token_type_ids.squeeze())\n",
        "\n",
        "              metrics_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "              metrics_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "  metrics = multi_labels_metrics(metrics_outputs, metrics_targets)\n",
        "  print((f\"EVAL METRICS: {metrics}\"))\n",
        "\n",
        "  return metrics\n"
      ],
      "metadata": {
        "id": "NA24sYKp8tvE"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFeKHNTX15ji",
        "outputId": "8a2d3dd7-0d21-4a64-e16e-97d2f65f22b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Epoch 1: Training Start   #############\n",
            "############# Epoch 1: Training End     #############\n",
            "############# Epoch 1: Validation Start   #############\n",
            "############# Epoch 1: Validation End     #############\n",
            "Epoch: 1 \tAvgerage Training Loss: 0.032807 \tAverage Validation Loss: 0.142531\n",
            "############# Epoch 1  Metrics   #############\n",
            "\n",
            "\n",
            "{'roc_auc': 0.6397058823529411, 'hamming_loss': 0.49411764705882355, 'f1': 0.5}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "       color_sum       0.43      1.00      0.60        22\n",
            "      threat_sum       0.00      0.00      0.00         3\n",
            "      fading_sum       0.14      1.00      0.24         6\n",
            "        form_sum       0.43      0.89      0.58        18\n",
            "kinesthetics_sum       0.37      1.00      0.54        19\n",
            "\n",
            "       micro avg       0.34      0.93      0.50        68\n",
            "       macro avg       0.27      0.78      0.39        68\n",
            "    weighted avg       0.37      0.93      0.52        68\n",
            "     samples avg       0.36      0.94      0.49        68\n",
            "\n",
            "############# Epoch 1  Done   #############\n",
            "\n",
            "############# Epoch 2: Training Start   #############\n",
            "############# Epoch 2: Training End     #############\n",
            "############# Epoch 2: Validation Start   #############\n",
            "############# Epoch 2: Validation End     #############\n",
            "Epoch: 2 \tAvgerage Training Loss: 0.029183 \tAverage Validation Loss: 0.127634\n",
            "############# Epoch 2  Metrics   #############\n",
            "\n",
            "\n",
            "{'roc_auc': 0.7192513368983957, 'hamming_loss': 0.32941176470588235, 'f1': 0.5714285714285714}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "       color_sum       0.45      0.95      0.61        22\n",
            "      threat_sum       0.00      0.00      0.00         3\n",
            "      fading_sum       0.00      0.00      0.00         6\n",
            "        form_sum       0.52      0.94      0.67        18\n",
            "kinesthetics_sum       0.38      0.95      0.54        19\n",
            "\n",
            "       micro avg       0.44      0.82      0.57        68\n",
            "       macro avg       0.27      0.57      0.36        68\n",
            "    weighted avg       0.39      0.82      0.52        68\n",
            "     samples avg       0.46      0.85      0.56        68\n",
            "\n",
            "############# Epoch 2  Done   #############\n",
            "\n",
            "############# Epoch 3: Training Start   #############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Epoch 3: Training End     #############\n",
            "############# Epoch 3: Validation Start   #############\n",
            "############# Epoch 3: Validation End     #############\n",
            "Epoch: 3 \tAvgerage Training Loss: 0.026712 \tAverage Validation Loss: 0.117788\n",
            "############# Epoch 3  Metrics   #############\n",
            "\n",
            "\n",
            "{'roc_auc': 0.7172459893048128, 'hamming_loss': 0.21568627450980393, 'f1': 0.5864661654135338}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "       color_sum       0.73      0.73      0.73        22\n",
            "      threat_sum       0.00      0.00      0.00         3\n",
            "      fading_sum       0.00      0.00      0.00         6\n",
            "        form_sum       0.49      1.00      0.65        18\n",
            "kinesthetics_sum       0.83      0.26      0.40        19\n",
            "\n",
            "       micro avg       0.60      0.57      0.59        68\n",
            "       macro avg       0.41      0.40      0.36        68\n",
            "    weighted avg       0.60      0.57      0.52        68\n",
            "     samples avg       0.62      0.62      0.60        68\n",
            "\n",
            "############# Epoch 3  Done   #############\n",
            "\n",
            "############# Epoch 4: Training Start   #############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Epoch 4: Training End     #############\n",
            "############# Epoch 4: Validation Start   #############\n",
            "############# Epoch 4: Validation End     #############\n",
            "Epoch: 4 \tAvgerage Training Loss: 0.025446 \tAverage Validation Loss: 0.109557\n",
            "############# Epoch 4  Metrics   #############\n",
            "\n",
            "\n",
            "{'roc_auc': 0.7713903743315508, 'hamming_loss': 0.1843137254901961, 'f1': 0.6618705035971224}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "       color_sum       0.77      0.77      0.77        22\n",
            "      threat_sum       0.00      0.00      0.00         3\n",
            "      fading_sum       0.00      0.00      0.00         6\n",
            "        form_sum       0.53      1.00      0.69        18\n",
            "kinesthetics_sum       0.73      0.58      0.65        19\n",
            "\n",
            "       micro avg       0.65      0.68      0.66        68\n",
            "       macro avg       0.41      0.47      0.42        68\n",
            "    weighted avg       0.60      0.68      0.61        68\n",
            "     samples avg       0.64      0.70      0.65        68\n",
            "\n",
            "############# Epoch 4  Done   #############\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "trained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, ckpt_path, best_model_path, df_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST"
      ],
      "metadata": {
        "id": "BFJgtECyBvt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "ti3K0jiLBox7"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics =  compute_test_metrics(test_data_loader)"
      ],
      "metadata": {
        "id": "HWePtx-juAM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92a936f-562d-4b46-f53f-777c4927e8b6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'roc_auc': 0.5, 'hamming_loss': 0.7368421052631579, 'f1': 0.4166666666666667}\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "       color_sum       0.39      1.00      0.57        15\n",
            "      threat_sum       0.16      1.00      0.27         6\n",
            "      fading_sum       0.08      1.00      0.15         3\n",
            "        form_sum       0.34      1.00      0.51        13\n",
            "kinesthetics_sum       0.34      1.00      0.51        13\n",
            "\n",
            "       micro avg       0.26      1.00      0.42        50\n",
            "       macro avg       0.26      1.00      0.40        50\n",
            "    weighted avg       0.32      1.00      0.48        50\n",
            "     samples avg       0.26      1.00      0.41        50\n",
            "\n",
            "EVAL METRICS: {'roc_auc': 0.5, 'hamming_loss': 0.7368421052631579, 'f1': 0.4166666666666667}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}