{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-GV8nLI2AXD",
        "outputId": "cc15da49-7393-4a79-cc12-ccb404605326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/542.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/542.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BRCz44s2_5s",
        "outputId": "4806e601-5529-4123-cc34-a063bbcbcfe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cpNn76Ej2b7Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import shutil\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NAEtmzK-AIRj"
      },
      "outputs": [],
      "source": [
        "def pre_process_data(df, test_proportion, train_size):\n",
        "\n",
        "    size_df = df.shape[0]\n",
        "    df = shuffle(df)\n",
        "    X = df[[\"FQText\"]]\n",
        "    y = df.drop([\"FQText\"], axis=1)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_proportion, shuffle=True, random_state=42)\n",
        "\n",
        "    df_train = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\n",
        "    df_test = pd.concat([X_test, y_test], axis=1).reset_index(drop=True)\n",
        "    df_labels = list(df.columns)[2:] # popping the automatic unnamed and the text column\n",
        "\n",
        "    train_df = df_train.sample(frac=train_size, random_state=42).reset_index(drop=True)\n",
        "    val_df = df_train.drop(train_df.index).reset_index(drop=True)\n",
        "\n",
        "    print(\"Total amount of data: {}\".format(size_df))\n",
        "    print(\"Number of rows used to TRAIN: {}\".format(train_df.shape[0]))\n",
        "    print(\"Number of rows used to VALIDATE: {}\".format(val_df.shape[0]))\n",
        "    print(\"Number of rows used to TEST: {}\".format(df_test.shape[0]))\n",
        "\n",
        "    return train_df, val_df, df_test, df_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "020inJJS15jg"
      },
      "outputs": [],
      "source": [
        "def set_hyperparams(hp_dictionary):\n",
        "\n",
        "    MAX_LEN = hp_dictionary[\"MAX_LEN\"]\n",
        "    TRAIN_BATCH_SIZE = hp_dictionary[\"TRAIN_BATCH_SIZE\"]\n",
        "    VALID_BATCH_SIZE = hp_dictionary[\"VALID_BATCH_SIZE\"]\n",
        "    EPOCHS = hp_dictionary[\"EPOCHS\"]\n",
        "    LEARNING_RATE = hp_dictionary[\"LEARNING_RATE\"]\n",
        "\n",
        "    return MAX_LEN, TRAIN_BATCH_SIZE, VALID_BATCH_SIZE, EPOCHS, LEARNING_RATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MFhEjXxU15jg"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into\n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # return model, optimizer, epoch value, min validation loss\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n",
        "\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "By6QjBoA15jh"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.title = df['FQText']\n",
        "        # self.labels = list(df.columns)[2:] # list of the target values\n",
        "        self.targets = self.df[df_labels].values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True, # do we actually need special tokens ??\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'  # pytorch tensors\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
        "            'targets': torch.FloatTensor(self.targets[index])\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JfND4miy15jh"
      },
      "outputs": [],
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.linear = torch.nn.Linear(768, len(df_labels)) # have to changet he n of possible labels here\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
        "        output = self.bert_model(\n",
        "            input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        # the issue is that bert gets size 6 here?\n",
        "        output_dropout = self.dropout(output.pooler_output)\n",
        "        # print(output_dropout)\n",
        "        output = self.linear(output_dropout)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rD0OObyw15jh"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    # print(outputs, targets)\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1inxJZtT15jh"
      },
      "outputs": [],
      "source": [
        "def train_model(n_epochs, training_loader, validation_loader, model,\n",
        "                optimizer, checkpoint_path, best_model_path):\n",
        "  # initialize tracker for minimum validation loss\n",
        "  valid_loss_min = np.Inf\n",
        "\n",
        "\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    print('############# Epoch {}: Training Start   #############'.format(epoch))\n",
        "    for batch_idx, data in enumerate(training_loader):\n",
        "        # print('yyy epoch', batch_idx)\n",
        "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        \"\"\"targets are the y array of the original data. it contains the 25 labels.\n",
        "        The issue is: the outputs predicted are of size 6 for some reason\n",
        "        \"\"\"\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        #if batch_idx%5000==0:\n",
        "         #   print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print('before loss data in training', loss.item(), train_loss)\n",
        "        train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
        "        #print('after loss data in training', loss.item(), train_loss)\n",
        "\n",
        "    print('############# Epoch {}: Training End     #############'.format(epoch))\n",
        "\n",
        "    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n",
        "    ######################\n",
        "    # validate the model #\n",
        "    ######################\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, data in enumerate(validation_loader, 0):\n",
        "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
        "            val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "\n",
        "      predictions = []\n",
        "      # print(val_outputs[0])\n",
        "      for array_prob in val_outputs:\n",
        "        pred = list(np.where(np.array(array_prob) > proba_threshold, 1.0, 0.0 ))\n",
        "        if 1 not in pred:\n",
        "          idx = np.argmax(array_prob)\n",
        "          # print(idx)\n",
        "          pred[idx] = 1.0\n",
        "\n",
        "        predictions.append(pred)\n",
        "      # print(predictions[0])\n",
        "      # print(val_targets[0])\n",
        "\n",
        "      val_f1 = f1_score(predictions, val_targets, average=\"weighted\")\n",
        "      val_acc = accuracy_score(predictions, val_targets)\n",
        "      class_report = classification_report(predictions, val_targets)\n",
        "      print((f\"Accuracy: {val_f1}\"))\n",
        "      print((f\"F1 Score (Weighted): {val_f1}\"))\n",
        "      print((f\"Classification report: \\n{class_report}\"))\n",
        "\n",
        "\n",
        "      print('############# Epoch {}: Validation End     #############'.format(epoch))\n",
        "      # calculate average losses\n",
        "      #print('before cal avg train loss', train_loss)\n",
        "      train_loss = train_loss/len(training_loader)\n",
        "      valid_loss = valid_loss/len(validation_loader)\n",
        "      # print training/validation statistics\n",
        "      print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "\n",
        "      # create checkpoint variable and add important data\n",
        "      checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': valid_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "      }\n",
        "\n",
        "        # save checkpoint\n",
        "      save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "\n",
        "      ## TODO: save the model if validation loss has decreased\n",
        "      if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "        # save checkpoint as best model\n",
        "        save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "    print('############# Epoch {}  Done   #############\\n'.format(epoch))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN AND VALIDATION LOOP"
      ],
      "metadata": {
        "id": "K-rvtFb1ByjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"nancy_determinants\")"
      ],
      "metadata": {
        "id": "YO1ZAHm2pH0Q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwsqVD3wpIQ1",
        "outputId": "aa796f85-a271-4cea-95fa-3db818aa11c4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Réponse (French)', 'Answer (English)', 'Déterminant', 'C', 'C'', 'C'F',\n",
              "       'CF', 'CF'', 'CLOB', 'CLOBF', 'E', 'EF', 'F', 'FC', 'FC'', 'FCLOB',\n",
              "       'FE', 'K', 'KAN', 'KOB', 'KP'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns = {\"Answer (English)\": \"FQText\"}, inplace=True)\n",
        "\n",
        "df.drop(['Déterminant', 'Réponse (French)'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "cbDvsEuK43vS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_dictionary = {\"MAX_LEN\":256 ,\n",
        "    \"TRAIN_BATCH_SIZE\": 16,\n",
        "    \"VALID_BATCH_SIZE\": 16,\n",
        "    \"EPOCHS\": 4,\n",
        "    \"LEARNING_RATE\": 1e-05\n",
        "}"
      ],
      "metadata": {
        "id": "HOx4W-iAplm2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thCkEarT_sEz",
        "outputId": "211b4570-13d9-411e-ba58-1dbacdd86a47"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "I-BxMEEb15jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c87dc15-7edc-4f4e-c4bf-48033bb719bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total amount of data: 380\n",
            "Number of rows used to TRAIN: 325\n",
            "Number of rows used to VALIDATE: 36\n",
            "Number of rows used to TEST: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN, TRAIN_BATCH_SIZE, VALID_BATCH_SIZE, EPOCHS, LEARNING_RATE = set_hyperparams(hp_dictionary)\n",
        "\n",
        "test_proportion = 0.05\n",
        "test_size = 0.9\n",
        "\n",
        "train_df, val_df, df_test, df_labels  = pre_process_data(df, test_proportion, test_size)\n",
        "\n",
        "\n",
        "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
        "valid_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "proba_threshold = 0.5\n",
        "val_targets=[]\n",
        "val_outputs=[]\n",
        "\n",
        "ckpt_path = \"curr_ckpt\"\n",
        "best_model_path = \"best_model.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFeKHNTX15ji",
        "outputId": "8a14acea-c657-4f05-e3c2-808f1cf44186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Epoch 1: Training Start   #############\n",
            "############# Epoch 1: Training End     #############\n",
            "############# Epoch 1: Validation Start   #############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2564402810304449\n",
            "F1 Score (Weighted): 0.2564402810304449\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       1.00      0.17      0.29        36\n",
            "          14       1.00      0.12      0.21        25\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.20      0.15      0.17        61\n",
            "   macro avg       0.12      0.02      0.03        61\n",
            "weighted avg       1.00      0.15      0.26        61\n",
            " samples avg       0.22      0.15      0.18        61\n",
            "\n",
            "############# Epoch 1: Validation End     #############\n",
            "Epoch: 1 \tAvgerage Training Loss: 0.029718 \tAverage Validation Loss: 0.176803\n",
            "Validation loss decreased (inf --> 0.176803).  Saving model ...\n",
            "############# Epoch 1  Done   #############\n",
            "\n",
            "############# Epoch 2: Training Start   #############\n",
            "############# Epoch 2: Training End     #############\n",
            "############# Epoch 2: Validation Start   #############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2844657985573315\n",
            "F1 Score (Weighted): 0.2844657985573315\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.17      0.31      0.22        13\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       1.00      0.20      0.34        59\n",
            "          14       0.50      0.12      0.19        25\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.21      0.20      0.20        97\n",
            "   macro avg       0.10      0.04      0.04        97\n",
            "weighted avg       0.76      0.20      0.28        97\n",
            " samples avg       0.24      0.22      0.22        97\n",
            "\n",
            "############# Epoch 2: Validation End     #############\n",
            "Epoch: 2 \tAvgerage Training Loss: 0.023259 \tAverage Validation Loss: 0.142091\n",
            "Validation loss decreased (0.176803 --> 0.142091).  Saving model ...\n",
            "############# Epoch 2  Done   #############\n",
            "\n",
            "############# Epoch 3: Training Start   #############\n",
            "############# Epoch 3: Training End     #############\n",
            "############# Epoch 3: Validation Start   #############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.31013860089490336\n",
            "F1 Score (Weighted): 0.31013860089490336\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.44      0.33      0.38        49\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.67      0.20      0.31        59\n",
            "          14       0.33      0.12      0.18        25\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.23      0.23      0.23       133\n",
            "   macro avg       0.08      0.04      0.05       133\n",
            "weighted avg       0.52      0.23      0.31       133\n",
            " samples avg       0.27      0.25      0.26       133\n",
            "\n",
            "############# Epoch 3: Validation End     #############\n",
            "Epoch: 3 \tAvgerage Training Loss: 0.019224 \tAverage Validation Loss: 0.121605\n",
            "Validation loss decreased (0.142091 --> 0.121605).  Saving model ...\n",
            "############# Epoch 3  Done   #############\n",
            "\n",
            "############# Epoch 4: Training Start   #############\n",
            "############# Epoch 4: Training End     #############\n",
            "############# Epoch 4: Validation Start   #############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3367086905450888\n",
            "F1 Score (Weighted): 0.3367086905450888\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.58      0.33      0.42        85\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.50      0.20      0.29        59\n",
            "          14       0.25      0.12      0.16        25\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.24      0.25      0.25       169\n",
            "   macro avg       0.08      0.04      0.05       169\n",
            "weighted avg       0.50      0.25      0.34       169\n",
            " samples avg       0.28      0.27      0.28       169\n",
            "\n",
            "############# Epoch 4: Validation End     #############\n",
            "Epoch: 4 \tAvgerage Training Loss: 0.016728 \tAverage Validation Loss: 0.108080\n",
            "Validation loss decreased (0.121605 --> 0.108080).  Saving model ...\n",
            "############# Epoch 4  Done   #############\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, ckpt_path, best_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST"
      ],
      "metadata": {
        "id": "BFJgtECyBvt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "ti3K0jiLBox7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_targets = []\n",
        "val_outputs= []"
      ],
      "metadata": {
        "id": "z7YOjAnGC1kh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "      for batch_idx, data in enumerate(test_data_loader, 0):\n",
        "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "\n",
        "      predictions = []\n",
        "      # print(val_outputs[0])\n",
        "      for array_prob in val_outputs:\n",
        "        pred = list(np.where(np.array(array_prob) > proba_threshold, 1.0, 0.0 ))\n",
        "        if 1 not in pred:\n",
        "          idx = np.argmax(array_prob)\n",
        "          # print(idx)\n",
        "          pred[idx] = 1.0\n",
        "\n",
        "        predictions.append(pred)\n",
        "      # print(predictions[0])\n",
        "      # print(val_targets[0])\n",
        "\n",
        "      val_f1 = f1_score(predictions, val_targets, average=\"weighted\")\n",
        "      val_acc = accuracy_score(predictions, val_targets)\n",
        "      class_report = classification_report(predictions, val_targets)\n",
        "      print((f\"Accuracy: {val_f1}\"))\n",
        "      print((f\"F1 Score (Weighted): {val_f1}\"))\n",
        "      print((f\"Classification report: \\n{class_report}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wKJDpcUCTmu",
        "outputId": "ff9bcd9c-b3ad-441c-8ae2-2f467f144e1b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.48\n",
            "F1 Score (Weighted): 0.48\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       1.00      0.32      0.48        19\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.00      0.00      0.00         0\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.29      0.32      0.30        19\n",
            "   macro avg       0.06      0.02      0.03        19\n",
            "weighted avg       1.00      0.32      0.48        19\n",
            " samples avg       0.32      0.32      0.32        19\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}