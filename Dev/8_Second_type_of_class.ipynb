{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juzcWoi2peIY",
        "outputId": "74d250b1-f075-4158-ac2f-8c6be1193261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U accelerate\n",
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig, BertModel\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics.cluster import contingency_matrix\n",
        "\n",
        "import shutil\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "UhITiP2OqZpY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"nancy_determinants_grouped.csv\")\n"
      ],
      "metadata": {
        "id": "kd5k0YVTpwNj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns = {\"Answer (English)\": \"FQText\"}, inplace=True)\n",
        "\n",
        "df.drop(['Déterminant', 'C', 'C\\'', 'C\\'F',\n",
        "       'CF', 'CF\\'', 'CLOB', 'CLOBF', 'E', 'EF', 'F', 'FC', 'FC\\'', 'FCLOB',\n",
        "       'FE', 'K', 'KAN', 'KOB', 'KP', 'Réponse (French)'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "-p4VALtPqVSm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWE-iebnreMQ",
        "outputId": "3e64ca6b-05d3-48b9-ebfb-d9ea0004b159"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 380 entries, 0 to 379\n",
            "Data columns (total 6 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   FQText            380 non-null    object\n",
            " 1   color_sum         380 non-null    int64 \n",
            " 2   threat_sum        380 non-null    int64 \n",
            " 3   fading_sum        380 non-null    int64 \n",
            " 4   form_sum          380 non-null    int64 \n",
            " 5   kinesthetics_sum  380 non-null    int64 \n",
            "dtypes: int64(5), object(1)\n",
            "memory usage: 17.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DNgCHUrsGOY",
        "outputId": "35ccb317-242b-4480-b278-def703ec9ca6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['FQText', 'color_sum', 'threat_sum', 'fading_sum', 'form_sum',\n",
              "       'kinesthetics_sum'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "SoGrmtzosPTE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.astype({'color_sum': np.float32, 'threat_sum': np.float32, 'fading_sum': np.float32, 'form_sum': np.float32,\n",
        "       'kinesthetics_sum': np.float32})"
      ],
      "metadata": {
        "id": "ui7DkJeqrxLZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iiwkMzzsVFW",
        "outputId": "ef3785a6-89ea-4ce7-9c52-096f6f98bcd4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 380 entries, 0 to 379\n",
            "Data columns (total 6 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   FQText            380 non-null    object \n",
            " 1   color_sum         380 non-null    float32\n",
            " 2   threat_sum        380 non-null    float32\n",
            " 3   fading_sum        380 non-null    float32\n",
            " 4   form_sum          380 non-null    float32\n",
            " 5   kinesthetics_sum  380 non-null    float32\n",
            "dtypes: float32(5), object(1)\n",
            "memory usage: 10.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process_data(df, test_proportion, train_size):\n",
        "\n",
        "    size_df = df.shape[0]\n",
        "    df = shuffle(df)\n",
        "    X = df[[\"FQText\"]]\n",
        "    y = df.drop([\"FQText\"], axis=1)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_proportion, shuffle=True, random_state=42)\n",
        "\n",
        "    df_train = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\n",
        "    df_test = pd.concat([X_test, y_test], axis=1).reset_index(drop=True)\n",
        "    df_labels = list(y.columns)\n",
        "\n",
        "    print(df_labels)\n",
        "\n",
        "    train_df = df_train.sample(frac=train_size, random_state=42).reset_index(drop=True)\n",
        "    val_df = df_train.drop(train_df.index).reset_index(drop=True)\n",
        "\n",
        "    print(\"Total amount of data: {}\".format(size_df))\n",
        "    print(\"Number of rows used to TRAIN: {}\".format(train_df.shape[0]))\n",
        "    print(\"Number of rows used to VALIDATE: {}\".format(val_df.shape[0]))\n",
        "    print(\"Number of rows used to TEST: {}\".format(df_test.shape[0]))\n",
        "\n",
        "    return train_df, val_df, df_test, df_labels"
      ],
      "metadata": {
        "id": "0NbbfdCYqRiO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"FQText\"].str.len().plot.hist(bins=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "OrNNPAqlqVoS",
        "outputId": "ae61efe5-6acf-41db-b1a6-f0f7b5122d75"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 256"
      ],
      "metadata": {
        "id": "p_LyHE6Xt7cR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizer, AutoTokenizer\n",
        "from transformers import DistilBertForSequenceClassification, AutoModelForSequenceClassification\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "9hCIqmgVskQb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df, df_test, df_labels = pre_process_data(df, 0.1, 0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7CVzYKbsuoa",
        "outputId": "187a1c13-4b2c-4a8f-9919-891b9d62a5c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['color_sum', 'threat_sum', 'fading_sum', 'form_sum', 'kinesthetics_sum']\n",
            "Total amount of data: 380\n",
            "Number of rows used to TRAIN: 274\n",
            "Number of rows used to VALIDATE: 68\n",
            "Number of rows used to TEST: 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
        "model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=len(df_labels),\n",
        "                                                            problem_type=\"multi_label_classification\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLLoVeYHs4v1",
        "outputId": "caf123bd-a895-41cb-f810-f92d0bc00bb0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class CustomDataset(Dataset):\n",
        "#   def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "#     self.texts = texts\n",
        "#     self.labels = labels\n",
        "#     self.tokenizer = tokenizer\n",
        "#     self.max_len = max_len\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.texts)\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#     text = str(self.texts[idx])\n",
        "#     label = torch.tensor(self.labels[idx])\n",
        "\n",
        "#     encoding = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors='pt')\n",
        "\n",
        "#     return {\n",
        "#         'input_ids': encoding['input_ids'].flatten(),\n",
        "#         'attention_mask': encoding['attention_mask'].flatten(),\n",
        "#         'labels': label\n",
        "#     }"
      ],
      "metadata": {
        "id": "TJQZk5i2tAWW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.texts = df['FQText']\n",
        "        self.targets = self.df[df_labels].values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.texts[index])\n",
        "        label = torch.tensor(self.targets[index])\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True, # do we actually need special tokens ??\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'  # pytorch tensors\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'token_type_ids': encoding[\"token_type_ids\"].flatten(),\n",
        "            'targets': torch.FloatTensor(self.targets[index])\n",
        "        }"
      ],
      "metadata": {
        "id": "zj8sthD9tGNx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
        "val_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "id": "rmvz1hgVt4YT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset[0]"
      ],
      "metadata": {
        "id": "8JXPZNElwTKq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, f1_score, hamming_loss\n",
        "from transformers import EvalPrediction\n",
        "import torch\n",
        "\n",
        "\n",
        "def multi_labels_metrics(predictions, targets, threshold=0.5): # mess with threshold\n",
        "  sigmoid = torch.nn.Sigmoid()\n",
        "  probs = sigmoid(torch.Tensor(predictions)) #mapply activation function in the raw values\n",
        "\n",
        "  y_pred = np.zeros(probs.shape)\n",
        "  y_pred[np.where(probs>=threshold)] = 1\n",
        "  y_true = targets\n",
        "\n",
        "  f1 = f1_score(y_true, y_pred, average = 'weighted')\n",
        "  roc_auc = roc_auc_score(y_true, y_pred, average = 'weighted')\n",
        "  hamming = hamming_loss(y_true, y_pred)\n",
        "\n",
        "  metrics = {\n",
        "      \"roc_auc\": roc_auc,       # special multilabel metrics\n",
        "      \"hamming_loss\": hamming,  # special multilabel metrics\n",
        "      \"f1\": f1\n",
        "  }\n",
        "\n",
        "  return metrics\n",
        "\n",
        "def compute_metrics(p:EvalPrediction):\n",
        "  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "\n",
        "  result = multi_labels_metrics(predictions=preds,\n",
        "                                targets=p.label_ids)\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "wg_7en7auFl6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    output_dir = './results',\n",
        "    num_train_epochs=3,\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model,\n",
        "                  args=args,\n",
        "                  train_dataset = train_dataset,\n",
        "                  eval_dataset = val_dataset,\n",
        "                  compute_metrics=compute_metrics)"
      ],
      "metadata": {
        "id": "KRpe-FrXuVAB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "ZhgQi4pfuhx3",
        "outputId": "cc2d09e1-e81f-4f1c-f76f-2281df35ede1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask,token_type_ids.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1860\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3138\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3179\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   3180\u001b[0m                     \u001b[0;34m\"The model did not return a loss from the inputs, only the following keys: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3181\u001b[0m                     \u001b[0;34mf\"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask,token_type_ids."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "j6xMj0NMuy8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}