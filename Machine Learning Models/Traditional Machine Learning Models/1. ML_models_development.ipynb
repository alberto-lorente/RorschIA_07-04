{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multilabel-classification Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model development with TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import hamming_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TF-IDF Model for Contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pre_process_data(df, test_proportion=0.1):\n",
        "\n",
        "    df.columns.values[0] = \"FQText\"\n",
        "    size_df = df.shape[0]\n",
        "\n",
        "    X = df[[\"FQText\"]].to_numpy()\n",
        "\n",
        "    y_df = df.drop([\"FQText\"], axis=1).astype(np.float32)\n",
        "    cols = df.columns\n",
        "    df_labels = list(y_df.columns)\n",
        "\n",
        "    y = y_df.to_numpy()\n",
        "\n",
        "    X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size=test_proportion)\n",
        "    \n",
        "    X_train = pd.DataFrame(X_train, columns=[\"FQText\"])\n",
        "    y_train = pd.DataFrame(y_train, columns=[df_labels], dtype=np.float32)\n",
        "    X_test = pd.DataFrame(X_test, columns=[\"FQText\"])\n",
        "    y_test = pd.DataFrame(y_test, columns=[df_labels], dtype=np.float32)\n",
        "\n",
        "    # print(df_labels)\n",
        "\n",
        "    # print(\"Total amount of data: {}\".format(size_df))\n",
        "    # print(\"Number of rows used to TRAIN: {}\".format(X_train.shape[0]))\n",
        "    # print(\"Number of rows used to TEST: {}\".format(X_test.shape[0]))\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, df_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfs = ['nancy_determinants_individual_labels_eng.csv',\n",
        " 'nancy_contents_individual_labels_eng.csv',\n",
        " 'nancy_contents_macro_labels_english.csv',\n",
        " 'nancy_determinants_macro_labels_english.csv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = [KNeighborsClassifier(), LogisticRegression(random_state=42, solver = \"liblinear\"), SVC(random_state=42), \n",
        "          RandomForestClassifier(random_state=42), SGDClassifier(random_state=42), GradientBoostingClassifier(random_state=42)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_tfidf(df_name, models=models):\n",
        "    \n",
        "    name = \"_\".join(df_name.split(\"_\")[1:3])\n",
        "    df = pd.read_csv(df_name)\n",
        "\n",
        "    X_train, y_train, X_test, y_test, df_labels = pre_process_data(df, test_proportion=0.1)\n",
        "\n",
        "    tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "    X_train_transformed = tfidf_vectorizer.fit_transform(X_train[\"FQText\"].to_list())\n",
        "    X_test_transformed = tfidf_vectorizer.transform(X_test[\"FQText\"].to_list())\n",
        "    \n",
        "    list_results = []\n",
        "\n",
        "    for model in models:\n",
        "        model_name = str(model).split(\"()\")[0]\n",
        "        dict_model_info = {\"data_model\": name,\n",
        "                            \"labels\": df_labels,\n",
        "                            \"ml_algo\":model_name}\n",
        "        one_v_rest = OneVsRestClassifier(model)\n",
        "\n",
        "        model_fit = one_v_rest.fit(X_train_transformed, y_train)\n",
        "\n",
        "        y_pred = model_fit.predict(X_test_transformed)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
        "        hamming = hamming_loss(y_test, y_pred)\n",
        "        \n",
        "        dict_model_info[\"accuracy\"] = accuracy\n",
        "        dict_model_info[\"f1\"] = f1\n",
        "        dict_model_info[\"hamming\"] = hamming\n",
        "        \n",
        "        list_results.append(dict_model_info)\n",
        "    return list_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = []\n",
        "for df in dfs:\n",
        "    results_per_df = model_tfidf(df)\n",
        "    results.extend(results_per_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results for the TF-IDF Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_tf = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_model</th>\n",
              "      <th>labels</th>\n",
              "      <th>ml_algo</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>hamming</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.626506</td>\n",
              "      <td>0.070455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.582278</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.494382</td>\n",
              "      <td>0.230769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.457143</td>\n",
              "      <td>0.194872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.215385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.406780</td>\n",
              "      <td>0.079545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>0.093182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>SVC(random_state=42)</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.393443</td>\n",
              "      <td>0.084091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.159091</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>0.038721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.321839</td>\n",
              "      <td>0.302564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.159091</td>\n",
              "      <td>0.313253</td>\n",
              "      <td>0.047980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
              "      <td>0.102564</td>\n",
              "      <td>0.245614</td>\n",
              "      <td>0.220513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.242424</td>\n",
              "      <td>0.042088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.078947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>0.067251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>SVC(random_state=42)</td>\n",
              "      <td>0.102564</td>\n",
              "      <td>0.148148</td>\n",
              "      <td>0.235897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.076023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.070175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.042088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>SVC(random_state=42)</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.042088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.064327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>SVC(random_state=42)</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.042553</td>\n",
              "      <td>0.065789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043771</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 data_model  \\\n",
              "16           contents_macro   \n",
              "12           contents_macro   \n",
              "22       determinants_macro   \n",
              "21       determinants_macro   \n",
              "23       determinants_macro   \n",
              "13           contents_macro   \n",
              "15           contents_macro   \n",
              "14           contents_macro   \n",
              "17           contents_macro   \n",
              "11      contents_individual   \n",
              "18       determinants_macro   \n",
              "10      contents_individual   \n",
              "19       determinants_macro   \n",
              "6       contents_individual   \n",
              "4   determinants_individual   \n",
              "5   determinants_individual   \n",
              "20       determinants_macro   \n",
              "0   determinants_individual   \n",
              "3   determinants_individual   \n",
              "9       contents_individual   \n",
              "8       contents_individual   \n",
              "1   determinants_individual   \n",
              "2   determinants_individual   \n",
              "7       contents_individual   \n",
              "\n",
              "                                               labels  \\\n",
              "16  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "12  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "22  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "21  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "23  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "13  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "15  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "14  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "17  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "11  [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "18  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "10  [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "19  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "6   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "4   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "5   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "20  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "0   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "3   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "9   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "8   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "1   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "2   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "7   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "\n",
              "                                              ml_algo  accuracy        f1  \\\n",
              "16                     SGDClassifier(random_state=42)  0.450000  0.626506   \n",
              "12                               KNeighborsClassifier  0.475000  0.582278   \n",
              "22                     SGDClassifier(random_state=42)  0.307692  0.494382   \n",
              "21            RandomForestClassifier(random_state=42)  0.282051  0.457143   \n",
              "23        GradientBoostingClassifier(random_state=42)  0.153846  0.432432   \n",
              "13  LogisticRegression(random_state=42, solver='li...  0.300000  0.406780   \n",
              "15            RandomForestClassifier(random_state=42)  0.325000  0.405797   \n",
              "14                               SVC(random_state=42)  0.300000  0.393443   \n",
              "17        GradientBoostingClassifier(random_state=42)  0.200000  0.375000   \n",
              "11        GradientBoostingClassifier(random_state=42)  0.159091  0.361111   \n",
              "18                               KNeighborsClassifier  0.230769  0.321839   \n",
              "10                     SGDClassifier(random_state=42)  0.159091  0.313253   \n",
              "19  LogisticRegression(random_state=42, solver='li...  0.102564  0.245614   \n",
              "6                                KNeighborsClassifier  0.136364  0.242424   \n",
              "4                      SGDClassifier(random_state=42)  0.157895  0.181818   \n",
              "5         GradientBoostingClassifier(random_state=42)  0.000000  0.178571   \n",
              "20                               SVC(random_state=42)  0.102564  0.148148   \n",
              "0                                KNeighborsClassifier  0.105263  0.133333   \n",
              "3             RandomForestClassifier(random_state=42)  0.078947  0.111111   \n",
              "9             RandomForestClassifier(random_state=42)  0.045455  0.074074   \n",
              "8                                SVC(random_state=42)  0.045455  0.074074   \n",
              "1   LogisticRegression(random_state=42, solver='li...  0.026316  0.043478   \n",
              "2                                SVC(random_state=42)  0.026316  0.042553   \n",
              "7   LogisticRegression(random_state=42, solver='li...  0.000000  0.000000   \n",
              "\n",
              "     hamming  \n",
              "16  0.070455  \n",
              "12  0.075000  \n",
              "22  0.230769  \n",
              "21  0.194872  \n",
              "23  0.215385  \n",
              "13  0.079545  \n",
              "15  0.093182  \n",
              "14  0.084091  \n",
              "17  0.090909  \n",
              "11  0.038721  \n",
              "18  0.302564  \n",
              "10  0.047980  \n",
              "19  0.220513  \n",
              "6   0.042088  \n",
              "4   0.078947  \n",
              "5   0.067251  \n",
              "20  0.235897  \n",
              "0   0.076023  \n",
              "3   0.070175  \n",
              "9   0.042088  \n",
              "8   0.042088  \n",
              "1   0.064327  \n",
              "2   0.065789  \n",
              "7   0.043771  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_results_tf.sort_values(\"f1\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_tf.to_csv(\"tf_models.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pickle.dump(model, open(r\"..\\Models\\Contents\\pipeline_contents_One-Many_V4-11-05.sav\", 'wb')) \n",
        "\n",
        "# will save the RF model since it was at the end of the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# pickle.dump(model, open(r\"..\\Models\\Determinants\\pipeline_determinants_One-Many_V4-11-05.sav\", 'wb'))\n",
        "\n",
        "# will save the RF model by default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function to get the predictions back from the tf idf classifier for the individual labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list(y_determinants.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list(y_contents.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the model is tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# def evaluate_one_vs_rest_TFIDF(path, text):\n",
        "    \n",
        "#     pipeline = pickle.load(open(path, \"rb\"))\n",
        "    \n",
        "#     if \"content\" in path:\n",
        "#         # print(\"content found\")\n",
        "#         possible_outcomes = ['(A)', '(Ad)', '(H)', '(Hd)', 'A', 'Abs', 'Ad', 'Alim', 'Anat', 'Art',\n",
        "#        'Bot', 'Elem', 'Frag', 'Ge', 'H', 'Hd', 'Id', 'Nat', 'Obj', 'Pays', 'Radio', 'Sc', 'Sex', 'Sg', 'Vet']\n",
        "        \n",
        "#     elif \"determinant\" in path:\n",
        "#         # print(\"determinant found\")\n",
        "#         possible_outcomes = ['C', 'C\\'', 'C\\'F', 'CF', 'E', 'EF', 'F', 'FC', 'FC\\'', 'FE', 'K', 'kan']\n",
        "\n",
        "#     prediction = pipeline.predict([text])\n",
        "#     probabilities = pipeline.predict_proba([text]) # sometimes no prediction is given back so we can take the outcome with the highest P instead\n",
        "\n",
        "#     # print(\"prediction:\", prediction)\n",
        "#     # print(\"probabilities:\", probabilities)\n",
        "    \n",
        "#     list_predictions = prediction.tolist()\n",
        "#     list_predictions = [x for sublist in list_predictions for x in sublist] # avoid lists with sublists\n",
        "\n",
        "    \n",
        "#     if len(list_predictions) != len(possible_outcomes): # sanity check\n",
        "#         print(prediction)\n",
        "#         print( len(list_predictions)  )\n",
        "#         print(possible_outcomes)\n",
        "#         print( len(possible_outcomes)  )\n",
        "#         print(\"Error encountered in the predictions\")\n",
        "        \n",
        "#     results = ([possible_outcomes[i] for i in range(len(list_predictions)) if list_predictions[i] == 1]) \n",
        "\n",
        "#     if results == []:\n",
        "#         # print(\"No result\")\n",
        "#         i = probabilities.argmax(1).item()\n",
        "#         # print(ix)\n",
        "#         final_results = possible_outcomes[i]\n",
        "    \n",
        "#     else:\n",
        "#         final_results = str(results).replace(\"\\'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "    \n",
        "#     return final_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate_one_vs_rest_TFIDF(r\"..\\Models\\Contents\\pipeline_contents_One-Many_V3-18-04.sav\", \"Dog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate_one_vs_rest_TFIDF(r\"..\\Models\\Determinants\\pipeline_determinants_One-Many_V3-18-04.sav\", \"Dog\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model development with SentenceTransformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text_for_transformer(text):\n",
        "    \n",
        "    embeddings_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    \n",
        "    x_array = embeddings_model.encode(text, convert_to_numpy=True)\n",
        "    \n",
        "    x_centroid = np.mean(x_array)\n",
        "    X_transformers = x_centroid.reshape(-1,1)\n",
        "\n",
        "    \n",
        "    return X_transformers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pre_process_data(df, test_proportion=0.1):\n",
        "\n",
        "    df.columns.values[0] = \"FQText\"\n",
        "    size_df = df.shape[0]\n",
        "    df[\"FQText\"] = df[\"FQText\"].apply(preprocess_text_for_transformer)\n",
        "    X = df[[\"FQText\"]].to_numpy()\n",
        "\n",
        "    y_df = df.drop([\"FQText\"], axis=1).astype(np.float32)\n",
        "    cols = df.columns\n",
        "    df_labels = list(y_df.columns)\n",
        "\n",
        "    y = y_df.to_numpy()\n",
        "\n",
        "    X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size=test_proportion)\n",
        "    \n",
        "    X_train = pd.DataFrame(X_train, columns=[\"FQText\"])\n",
        "    y_train = pd.DataFrame(y_train, columns=[df_labels], dtype=np.float32)\n",
        "    \n",
        "    X_test = pd.DataFrame(X_test, columns=[\"FQText\"])\n",
        "    y_test = pd.DataFrame(y_test, columns=[df_labels], dtype=np.float32)\n",
        "\n",
        "    # print(df_labels)\n",
        "\n",
        "    # print(\"Total amount of data: {}\".format(size_df))\n",
        "    # print(\"Number of rows used to TRAIN: {}\".format(X_train.shape[0]))\n",
        "    # print(\"Number of rows used to TEST: {}\".format(X_test.shape[0]))\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, df_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_sentence_transformers(df_name, models=models):\n",
        "    \n",
        "    name = \"_\".join(df_name.split(\"_\")[1:3])\n",
        "    df = pd.read_csv(df_name)\n",
        "\n",
        "    X_train, y_train, X_test, y_test, df_labels = pre_process_data(df, test_proportion=0.1)\n",
        "    \n",
        "    list_results = []\n",
        "\n",
        "    for model in models:\n",
        "        model_name = str(model).split(\"()\")[0]\n",
        "        dict_model_info = {\"data_model\": name,\n",
        "                            \"labels\": df_labels,\n",
        "                            \"ml_algo\":model_name}\n",
        "        one_v_rest = OneVsRestClassifier(model)\n",
        "\n",
        "        model_fit = one_v_rest.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model_fit.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
        "        hamming = hamming_loss(y_test, y_pred)\n",
        "        \n",
        "        dict_model_info[\"accuracy\"] = accuracy\n",
        "        dict_model_info[\"f1\"] = f1\n",
        "        dict_model_info[\"hamming\"] = hamming\n",
        "        \n",
        "        list_results.append(dict_model_info)\n",
        "    return list_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for df in dfs:\n",
        "    results_per_df = model_sentence_transformers(df)\n",
        "    results.extend(results_per_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results for the Sentence Transformers Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_st = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_model</th>\n",
              "      <th>labels</th>\n",
              "      <th>ml_algo</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>hamming</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.412371</td>\n",
              "      <td>0.308108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.243243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.118182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.136364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.275676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>0.329114</td>\n",
              "      <td>0.120455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>SVC(random_state=42)</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.106818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.186047</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.072351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>RandomForestClassifier(random_state=42)</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.193548</td>\n",
              "      <td>0.109649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>0.172043</td>\n",
              "      <td>0.066322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.070175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.102339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.023256</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.051680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>contents_macro</td>\n",
              "      <td>[animal_sum, human_sum, abs_sum, food_sum, art...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>contents_individual</td>\n",
              "      <td>[(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...</td>\n",
              "      <td>SVC(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.248649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>SVC(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.248649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>determinants_individual</td>\n",
              "      <td>[C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...</td>\n",
              "      <td>SVC(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>determinants_macro</td>\n",
              "      <td>[color_sum, threat_sum, fading_sum, form_sum, ...</td>\n",
              "      <td>SGDClassifier(random_state=42)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.248649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 data_model  \\\n",
              "21       determinants_macro   \n",
              "18       determinants_macro   \n",
              "17           contents_macro   \n",
              "15           contents_macro   \n",
              "23       determinants_macro   \n",
              "12           contents_macro   \n",
              "14           contents_macro   \n",
              "9       contents_individual   \n",
              "3   determinants_individual   \n",
              "11      contents_individual   \n",
              "0   determinants_individual   \n",
              "5   determinants_individual   \n",
              "6       contents_individual   \n",
              "1   determinants_individual   \n",
              "13           contents_macro   \n",
              "10      contents_individual   \n",
              "7       contents_individual   \n",
              "16           contents_macro   \n",
              "4   determinants_individual   \n",
              "8       contents_individual   \n",
              "19       determinants_macro   \n",
              "20       determinants_macro   \n",
              "2   determinants_individual   \n",
              "22       determinants_macro   \n",
              "\n",
              "                                               labels  \\\n",
              "21  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "18  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "17  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "15  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "23  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "12  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "14  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "9   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "3   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "11  [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "0   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "5   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "6   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "1   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "13  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "10  [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "7   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "16  [animal_sum, human_sum, abs_sum, food_sum, art...   \n",
              "4   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "8   [(A), (AD), (H), (HD), A, ABS, AD, ALIM, ANAT,...   \n",
              "19  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "20  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "2   [C, C', C'F, CF, CF', CLOB, CLOBF, E, EF, F, F...   \n",
              "22  [color_sum, threat_sum, fading_sum, form_sum, ...   \n",
              "\n",
              "                                              ml_algo  accuracy        f1  \\\n",
              "21            RandomForestClassifier(random_state=42)  0.297297  0.412371   \n",
              "18                               KNeighborsClassifier  0.297297  0.400000   \n",
              "17        GradientBoostingClassifier(random_state=42)  0.250000  0.380952   \n",
              "15            RandomForestClassifier(random_state=42)  0.250000  0.375000   \n",
              "23        GradientBoostingClassifier(random_state=42)  0.270270  0.370370   \n",
              "12                               KNeighborsClassifier  0.275000  0.329114   \n",
              "14                               SVC(random_state=42)  0.200000  0.298507   \n",
              "9             RandomForestClassifier(random_state=42)  0.186047  0.222222   \n",
              "3             RandomForestClassifier(random_state=42)  0.210526  0.193548   \n",
              "11        GradientBoostingClassifier(random_state=42)  0.139535  0.172043   \n",
              "0                                KNeighborsClassifier  0.105263  0.142857   \n",
              "5         GradientBoostingClassifier(random_state=42)  0.105263  0.125000   \n",
              "6                                KNeighborsClassifier  0.023256  0.062500   \n",
              "1   LogisticRegression(random_state=42, solver='li...  0.000000  0.000000   \n",
              "13  LogisticRegression(random_state=42, solver='li...  0.000000  0.000000   \n",
              "10                     SGDClassifier(random_state=42)  0.000000  0.000000   \n",
              "7   LogisticRegression(random_state=42, solver='li...  0.000000  0.000000   \n",
              "16                     SGDClassifier(random_state=42)  0.000000  0.000000   \n",
              "4                      SGDClassifier(random_state=42)  0.000000  0.000000   \n",
              "8                                SVC(random_state=42)  0.000000  0.000000   \n",
              "19  LogisticRegression(random_state=42, solver='li...  0.000000  0.000000   \n",
              "20                               SVC(random_state=42)  0.000000  0.000000   \n",
              "2                                SVC(random_state=42)  0.000000  0.000000   \n",
              "22                     SGDClassifier(random_state=42)  0.000000  0.000000   \n",
              "\n",
              "     hamming  \n",
              "21  0.308108  \n",
              "18  0.243243  \n",
              "17  0.118182  \n",
              "15  0.136364  \n",
              "23  0.275676  \n",
              "12  0.120455  \n",
              "14  0.106818  \n",
              "9   0.072351  \n",
              "3   0.109649  \n",
              "11  0.066322  \n",
              "0   0.070175  \n",
              "5   0.102339  \n",
              "6   0.051680  \n",
              "1   0.064327  \n",
              "13  0.106818  \n",
              "10  0.044789  \n",
              "7   0.044789  \n",
              "16  0.106818  \n",
              "4   0.064327  \n",
              "8   0.044789  \n",
              "19  0.248649  \n",
              "20  0.248649  \n",
              "2   0.065789  \n",
              "22  0.248649  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_results_st.sort_values(\"f1\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_st.to_csv(\"sentence_transformers_models.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to get the label from the Sentence Transformer classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def preprocess_text_for_transformer(text):\n",
        "    \n",
        "#     embeddings_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    \n",
        "#     x_array = embeddings_model.encode(text, convert_to_numpy=True)\n",
        "    \n",
        "#     x_centroid = np.mean(x_array)\n",
        "#     X_transformers = x_centroid.reshape(-1,1)\n",
        "\n",
        "    \n",
        "#     return X_transformers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# preprocess_text_for_transformer(\"dog with two tails\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def evaluate_one_vs_rest_transformer(path, text):\n",
        "    \n",
        "#     pipeline = pickle.load(open(path, \"rb\"))\n",
        "    \n",
        "#     if \"content\" in path:\n",
        "#         # print(\"content found\")\n",
        "#         possible_outcomes = ['(A)', '(Ad)', '(H)', '(Hd)', 'A', 'Abs', 'Ad', 'Alim', 'Anat', 'Art',\n",
        "#        'Bot', 'Elem', 'Frag', 'Ge', 'H', 'Hd', 'Id', 'Nat', 'Obj', 'Pays', 'Radio', 'Sc', 'Sex', 'Sg', 'Vet']\n",
        "        \n",
        "#     elif \"determinant\" in path:\n",
        "#         # print(\"determinant found\")\n",
        "#         possible_outcomes = ['C', 'C\\'', 'C\\'F', 'CF', 'E', 'EF', 'F', 'FC', 'FC\\'', 'FE', 'K', 'kan']\n",
        "\n",
        "#     text_transformed = preprocess_text_for_transformer(text)\n",
        "    \n",
        "#     prediction = pipeline.predict([text_transformed])\n",
        "#     probabilities = pipeline.predict_proba([text_transformed]) # sometimes no prediction is given back so we can take the outcome with the highest P instead\n",
        "\n",
        "#     # print(\"prediction:\", prediction)\n",
        "#     # print(\"probabilities:\", probabilities)\n",
        "    \n",
        "#     list_predictions = prediction.tolist()\n",
        "#     list_predictions = [x for sublist in list_predictions for x in sublist] # avoid lists with sublists\n",
        "\n",
        "    \n",
        "#     if len(list_predictions) != len(possible_outcomes): # sanity check\n",
        "#         print(prediction)\n",
        "#         print( len(list_predictions)  )\n",
        "#         print(possible_outcomes)\n",
        "#         print( len(possible_outcomes)  )\n",
        "#         print(\"Error encountered in the predictions\")\n",
        "        \n",
        "#     results = ([possible_outcomes[i] for i in range(len(list_predictions)) if list_predictions[i] == 1]) \n",
        "\n",
        "#     if results == []:\n",
        "#         # print(\"No result\")\n",
        "#         i = probabilities.argmax(1).item()\n",
        "#         # print(ix)\n",
        "#         final_results = possible_outcomes[i]\n",
        "    \n",
        "#     else:\n",
        "#         final_results = str(results).replace(\"\\'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "    \n",
        "#     return final_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# preprocess_text_for_transformer(\"dog with tail\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate_one_vs_rest_transformer(r\"..\\Models\\Contents\\sentence_transformer_contents_V23-18-04.sav\", \"Dog with tail\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate_one_vs_rest_transformer(r\"..\\Models\\Determinants\\sentence_transformer_determinants_V23-18-04.sav\", \"Dog with tail\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
