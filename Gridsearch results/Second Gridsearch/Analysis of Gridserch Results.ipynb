{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_dicto_to_df_list(grid_list):\n",
    "    list_to_df = []\n",
    "    non_metrics = ['proba_outputs', 'actual_classes', 'proba_outputs', 'actual_classes', 'test_proba', 'test_actual_classes']\n",
    "    for dict_hyper in grid_list:\n",
    "        dict_to_df = {}\n",
    "        # print(dict_hyper)\n",
    "        for val in dict_hyper.values():\n",
    "            for item in val.items():\n",
    "                if type(item[1]) != dict:\n",
    "                    dict_to_df[item[0]] = item[1]\n",
    "                else:\n",
    "                    dictionary_results = item[1]\n",
    "                    for item in dictionary_results.items(): \n",
    "                        if item[0] not in non_metrics:\n",
    "                            dict_to_df[item[0]] = item[1]\n",
    "        list_to_df.append(dict_to_df)\n",
    "    return list_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial grid analysis of INDIVIDUAL DETERMINANT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"grid_results_determinants_individual.json\") as f:\n",
    "    grids = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_df = grid_dicto_to_df_list(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max-len</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>train_loss_epoch_1</th>\n",
       "      <th>valid_loss_epoch_1</th>\n",
       "      <th>f1_epoch_1</th>\n",
       "      <th>accuracy_epoch_1</th>\n",
       "      <th>roc_auc_epoch_1</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy_epoch_14</th>\n",
       "      <th>roc_auc_epoch_14</th>\n",
       "      <th>hamming_epoch_14</th>\n",
       "      <th>proba_outputs_epoch_14</th>\n",
       "      <th>actual_classes_epoch_14</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_hamming</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.070722</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.602192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.634606</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>[[[0.02805124595761299, 0.01598079316318035, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.069446</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.598310</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.020609</td>\n",
       "      <td>0.143677</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.638260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.614097</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>[[[0.056838832795619965, 0.040381889790296555,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.097712</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.601277</td>\n",
       "      <td>0.063889</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.027929</td>\n",
       "      <td>0.154011</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.618576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.590288</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>[[[0.05006634071469307, 0.04769202694296837, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.113145</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.624500</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.056068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.661716</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>[[[0.015534669160842896, 0.009569521993398666,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.064070</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.624500</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.113339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.660891</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>[[[0.022346261888742447, 0.015515814535319805,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.093663</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.621533</td>\n",
       "      <td>0.063889</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max-len  learning_rate  batch_size  num_train_epochs  n_epochs  \\\n",
       "0      128        0.00002           8                14        15   \n",
       "1      128        0.00002          12                14        15   \n",
       "2      128        0.00002          16                14        15   \n",
       "3      128        0.00003           8                14        15   \n",
       "4      128        0.00003          12                14        15   \n",
       "\n",
       "   train_loss_epoch_1  valid_loss_epoch_1  f1_epoch_1  accuracy_epoch_1  \\\n",
       "0            0.012611            0.070722    0.315789          0.250000   \n",
       "1            0.020609            0.143677    0.346667          0.361111   \n",
       "2            0.027929            0.154011    0.323529          0.277778   \n",
       "3            0.010827            0.056068    0.000000          0.000000   \n",
       "4            0.018558            0.113339    0.000000          0.000000   \n",
       "\n",
       "   roc_auc_epoch_1  ...  accuracy_epoch_14 roc_auc_epoch_14 hamming_epoch_14  \\\n",
       "0         0.602192  ...           0.333333         0.634606         0.061728   \n",
       "1         0.638260  ...           0.277778         0.614097         0.058642   \n",
       "2         0.618576  ...           0.222222         0.590288         0.061728   \n",
       "3         0.500000  ...           0.333333         0.661716         0.052469   \n",
       "4         0.500000  ...           0.361111         0.660891         0.054012   \n",
       "\n",
       "                              proba_outputs_epoch_14  \\\n",
       "0  [[[0.02805124595761299, 0.01598079316318035, 0...   \n",
       "1  [[[0.056838832795619965, 0.040381889790296555,...   \n",
       "2  [[[0.05006634071469307, 0.04769202694296837, 0...   \n",
       "3  [[[0.015534669160842896, 0.009569521993398666,...   \n",
       "4  [[[0.022346261888742447, 0.015515814535319805,...   \n",
       "\n",
       "                             actual_classes_epoch_14  test_loss   test_f1  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.069446  0.285714   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.097712  0.303030   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.113145  0.363636   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.064070  0.363636   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.093663  0.342857   \n",
       "\n",
       "   test_roc_auc  test_hamming  test_accuracy  \n",
       "0      0.598310      0.069444           0.25  \n",
       "1      0.601277      0.063889           0.25  \n",
       "2      0.624500      0.058333           0.30  \n",
       "3      0.624500      0.058333           0.25  \n",
       "4      0.621533      0.063889           0.25  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train_loss_epoch_14</th>\n",
       "      <th>valid_loss_epoch_14</th>\n",
       "      <th>f1_epoch_14</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_hamming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.064070</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.069446</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.069444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.039821</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.072222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>12</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.055813</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.093663</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.063889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>0.058668</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.097712</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.063889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.059746</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.102144</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>0.074256</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.113145</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>16</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.073092</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.116265</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.118486</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  batch_size  train_loss_epoch_14  valid_loss_epoch_14  \\\n",
       "3        0.00003           8             0.002068             0.039187   \n",
       "0        0.00002           8             0.003601             0.040578   \n",
       "6        0.00005           8             0.001423             0.039821   \n",
       "4        0.00003          12             0.004413             0.055813   \n",
       "1        0.00002          12             0.006030             0.058668   \n",
       "7        0.00005          12             0.003327             0.059746   \n",
       "2        0.00002          16             0.007666             0.074256   \n",
       "5        0.00003          16             0.006200             0.073092   \n",
       "8        0.00005          16             0.005776             0.071411   \n",
       "\n",
       "   f1_epoch_14  test_loss   test_f1  test_hamming  \n",
       "3     0.451613   0.064070  0.363636      0.058333  \n",
       "0     0.375000   0.069446  0.285714      0.069444  \n",
       "6     0.507463   0.071454  0.315789      0.072222  \n",
       "4     0.444444   0.093663  0.342857      0.063889  \n",
       "1     0.344828   0.097712  0.303030      0.063889  \n",
       "7     0.484848   0.102144  0.333333      0.066667  \n",
       "2     0.285714   0.113145  0.363636      0.058333  \n",
       "5     0.366667   0.116265  0.363636      0.058333  \n",
       "8     0.333333   0.118486  0.076923      0.066667  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_comparison = [\"learning_rate\", \"batch_size\" , \"train_loss_epoch_14\", \"valid_loss_epoch_14\", \"f1_epoch_14\", \"test_loss\", \"test_f1\", \"test_hamming\"]\n",
    "df[cols_comparison].sort_values([\"test_loss\"], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">train_loss_epoch_14</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valid_loss_epoch_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00002</th>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.058668</td>\n",
       "      <td>0.074256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00003</th>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>0.055813</td>\n",
       "      <td>0.073092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00005</th>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.039821</td>\n",
       "      <td>0.059746</td>\n",
       "      <td>0.071411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train_loss_epoch_14                     valid_loss_epoch_14  \\\n",
       "batch_size                     8         12        16                  8    \n",
       "learning_rate                                                               \n",
       "0.00002                  0.003601  0.006030  0.007666            0.040578   \n",
       "0.00003                  0.002068  0.004413  0.006200            0.039187   \n",
       "0.00005                  0.001423  0.003327  0.005776            0.039821   \n",
       "\n",
       "                                   \n",
       "batch_size           12        16  \n",
       "learning_rate                      \n",
       "0.00002        0.058668  0.074256  \n",
       "0.00003        0.055813  0.073092  \n",
       "0.00005        0.059746  0.071411  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table([\"train_loss_epoch_14\", \"valid_loss_epoch_14\"], index = \"learning_rate\", columns=\"batch_size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- We can see that generally the lower the batch size the faster a model will learn and the better a model will perform.\n",
    "\n",
    "We can scratch bath size 64 since we would need a higher learning rate and we may lose control of the pace of learning.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">train_loss_epoch_14</th>\n",
       "      <th colspan=\"3\" halign=\"left\">val_hamming</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valid_loss_epoch_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00002</th>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.058668</td>\n",
       "      <td>0.074256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00003</th>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.060185</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>0.055813</td>\n",
       "      <td>0.073092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00005</th>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>0.039821</td>\n",
       "      <td>0.059746</td>\n",
       "      <td>0.071411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train_loss_epoch_14                     val_hamming            \\\n",
       "batch_size                     8         12        16          8         12   \n",
       "learning_rate                                                                 \n",
       "0.00002                  0.003601  0.006030  0.007666    0.058642  0.058642   \n",
       "0.00003                  0.002068  0.004413  0.006200    0.047840  0.055556   \n",
       "0.00005                  0.001423  0.003327  0.005776    0.054012  0.055556   \n",
       "\n",
       "                        valid_loss_epoch_14                      \n",
       "batch_size           16                  8         12        16  \n",
       "learning_rate                                                    \n",
       "0.00002        0.058642            0.040578  0.058668  0.074256  \n",
       "0.00003        0.060185            0.039187  0.055813  0.073092  \n",
       "0.00005        0.054012            0.039821  0.059746  0.071411  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table([\"train_loss_epoch_14\", \"valid_loss_epoch_14\", \"val_hamming\"], index = \"learning_rate\", columns=\"batch_size\")\n",
    "\n",
    "#  Hamming loss is the fraction of labels that are incorrectly predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial grid analysis of INDIVIDUAL CONTENT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"grid_results_contents_individual.json\") as f:\n",
    "    grids = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grids = grids[-9:]\n",
    "len(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_df = grid_dicto_to_df_list(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['max-len', 'learning_rate', 'batch_size', 'num_train_epochs',\n",
       "       'n_epochs', 'train_loss_epoch_1', 'valid_loss_epoch_1', 'f1_epoch_1',\n",
       "       'accuracy_epoch_1', 'roc_auc_epoch_1',\n",
       "       ...\n",
       "       'accuracy_epoch_14', 'roc_auc_epoch_14', 'hamming_epoch_14',\n",
       "       'proba_outputs_epoch_14', 'actual_classes_epoch_14', 'test_loss',\n",
       "       'test_f1', 'test_roc_auc', 'test_hamming', 'test_accuracy'],\n",
       "      dtype='object', length=129)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max-len</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>train_loss_epoch_1</th>\n",
       "      <th>valid_loss_epoch_1</th>\n",
       "      <th>f1_epoch_1</th>\n",
       "      <th>accuracy_epoch_1</th>\n",
       "      <th>roc_auc_epoch_1</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy_epoch_14</th>\n",
       "      <th>roc_auc_epoch_14</th>\n",
       "      <th>hamming_epoch_14</th>\n",
       "      <th>proba_outputs_epoch_14</th>\n",
       "      <th>actual_classes_epoch_14</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_hamming</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.013059</td>\n",
       "      <td>0.060024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.583691</td>\n",
       "      <td>0.037940</td>\n",
       "      <td>[[[0.045712102204561234, 0.03578242287039757, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.041735</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.623325</td>\n",
       "      <td>0.032206</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>0.118099</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.04878</td>\n",
       "      <td>0.523685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.562886</td>\n",
       "      <td>0.038844</td>\n",
       "      <td>[[[0.04294946789741516, 0.03628834709525108, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.066843</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.621650</td>\n",
       "      <td>0.035427</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.028416</td>\n",
       "      <td>0.150349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.499057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.530971</td>\n",
       "      <td>0.041554</td>\n",
       "      <td>[[[0.06074479967355728, 0.03640878200531006, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.070685</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.603329</td>\n",
       "      <td>0.032206</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.583691</td>\n",
       "      <td>0.037940</td>\n",
       "      <td>[[[0.017957378178834915, 0.01750374212861061, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.664154</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.020290</td>\n",
       "      <td>0.095651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.563358</td>\n",
       "      <td>0.037940</td>\n",
       "      <td>[[[0.04086542874574661, 0.03246527910232544, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.059140</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.644996</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max-len  learning_rate  batch_size  num_train_epochs  n_epochs  \\\n",
       "0      128        0.00002           8                14        15   \n",
       "1      128        0.00002          12                14        15   \n",
       "2      128        0.00002          16                14        15   \n",
       "3      128        0.00003           8                14        15   \n",
       "4      128        0.00003          12                14        15   \n",
       "\n",
       "   train_loss_epoch_1  valid_loss_epoch_1  f1_epoch_1  accuracy_epoch_1  \\\n",
       "0            0.013059            0.060024    0.000000           0.00000   \n",
       "1            0.022386            0.118099    0.087912           0.04878   \n",
       "2            0.028416            0.150349    0.000000           0.00000   \n",
       "3            0.012464            0.050725    0.000000           0.00000   \n",
       "4            0.020290            0.095651    0.000000           0.00000   \n",
       "\n",
       "   roc_auc_epoch_1  ...  accuracy_epoch_14 roc_auc_epoch_14 hamming_epoch_14  \\\n",
       "0         0.500000  ...           0.170732         0.583691         0.037940   \n",
       "1         0.523685  ...           0.121951         0.562886         0.038844   \n",
       "2         0.499057  ...           0.073171         0.530971         0.041554   \n",
       "3         0.500000  ...           0.146341         0.583691         0.037940   \n",
       "4         0.500000  ...           0.121951         0.563358         0.037940   \n",
       "\n",
       "                              proba_outputs_epoch_14  \\\n",
       "0  [[[0.045712102204561234, 0.03578242287039757, ...   \n",
       "1  [[[0.04294946789741516, 0.03628834709525108, 0...   \n",
       "2  [[[0.06074479967355728, 0.03640878200531006, 0...   \n",
       "3  [[[0.017957378178834915, 0.01750374212861061, ...   \n",
       "4  [[[0.04086542874574661, 0.03246527910232544, 0...   \n",
       "\n",
       "                             actual_classes_epoch_14  test_loss   test_f1  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.041735  0.375000   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.066843  0.352941   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.070685  0.333333   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.033259  0.457143   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.059140  0.437500   \n",
       "\n",
       "   test_roc_auc  test_hamming  test_accuracy  \n",
       "0      0.623325      0.032206       0.217391  \n",
       "1      0.621650      0.035427       0.217391  \n",
       "2      0.603329      0.032206       0.173913  \n",
       "3      0.664154      0.030596       0.304348  \n",
       "4      0.644996      0.028986       0.260870  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train_loss_epoch_14</th>\n",
       "      <th>valid_loss_epoch_14</th>\n",
       "      <th>f1_epoch_14</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_hamming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.017364</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.029175</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.030596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.030596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.023577</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.041735</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.032206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.042689</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.022544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.040583</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.022544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>12</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.035016</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.059140</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.028986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>12</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.038378</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.066843</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.035427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.051646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069847</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.032206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>0.008648</td>\n",
       "      <td>0.051685</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.070685</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.032206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  batch_size  train_loss_epoch_14  valid_loss_epoch_14  \\\n",
       "6        0.00005           8             0.001978             0.017364   \n",
       "3        0.00003           8             0.002871             0.020008   \n",
       "0        0.00002           8             0.003716             0.023577   \n",
       "7        0.00005          12             0.003703             0.028062   \n",
       "8        0.00005          16             0.005484             0.040583   \n",
       "4        0.00003          12             0.005291             0.035016   \n",
       "1        0.00002          12             0.005903             0.038378   \n",
       "5        0.00003          16             0.008575             0.051646   \n",
       "2        0.00002          16             0.008648             0.051685   \n",
       "\n",
       "   f1_epoch_14  test_loss  test_accuracy   test_f1  test_hamming  \n",
       "6     0.493151   0.029175       0.434783  0.577778      0.030596  \n",
       "3     0.275862   0.033259       0.304348  0.457143      0.030596  \n",
       "0     0.275862   0.041735       0.217391  0.375000      0.032206  \n",
       "7     0.437500   0.042689       0.434783  0.666667      0.022544  \n",
       "8     0.492308   0.048579       0.434783  0.631579      0.022544  \n",
       "4     0.222222   0.059140       0.260870  0.437500      0.028986  \n",
       "1     0.218182   0.066843       0.217391  0.352941      0.035427  \n",
       "5     0.000000   0.069847       0.173913  0.333333      0.032206  \n",
       "2     0.115385   0.070685       0.173913  0.333333      0.032206  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_comparison = [\"learning_rate\", \"batch_size\" , \"train_loss_epoch_14\", \"valid_loss_epoch_14\", \"f1_epoch_14\", \"test_loss\", \"test_accuracy\", \"test_f1\", \"test_hamming\"]\n",
    "df[cols_comparison].sort_values(\"test_loss\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">train_loss_epoch_14</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valid_loss_epoch_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00002</th>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.008648</td>\n",
       "      <td>0.023577</td>\n",
       "      <td>0.038378</td>\n",
       "      <td>0.051685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00003</th>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.035016</td>\n",
       "      <td>0.051646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00005</th>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.017364</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>0.040583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train_loss_epoch_14                     valid_loss_epoch_14  \\\n",
       "batch_size                     8         12        16                  8    \n",
       "learning_rate                                                               \n",
       "0.00002                  0.003716  0.005903  0.008648            0.023577   \n",
       "0.00003                  0.002871  0.005291  0.008575            0.020008   \n",
       "0.00005                  0.001978  0.003703  0.005484            0.017364   \n",
       "\n",
       "                                   \n",
       "batch_size           12        16  \n",
       "learning_rate                      \n",
       "0.00002        0.038378  0.051685  \n",
       "0.00003        0.035016  0.051646  \n",
       "0.00005        0.028062  0.040583  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table([\"train_loss_epoch_14\", \"valid_loss_epoch_14\"], index = \"learning_rate\", columns=\"batch_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">train_loss_epoch_14</th>\n",
       "      <th colspan=\"3\" halign=\"left\">val_hamming</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valid_loss_epoch_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00002</th>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.008648</td>\n",
       "      <td>0.03794</td>\n",
       "      <td>0.038844</td>\n",
       "      <td>0.041554</td>\n",
       "      <td>0.023577</td>\n",
       "      <td>0.038378</td>\n",
       "      <td>0.051685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00003</th>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.03794</td>\n",
       "      <td>0.037940</td>\n",
       "      <td>0.042457</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.035016</td>\n",
       "      <td>0.051646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00005</th>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.02981</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.029810</td>\n",
       "      <td>0.017364</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>0.040583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train_loss_epoch_14                     val_hamming            \\\n",
       "batch_size                     8         12        16          8         12   \n",
       "learning_rate                                                                 \n",
       "0.00002                  0.003716  0.005903  0.008648     0.03794  0.038844   \n",
       "0.00003                  0.002871  0.005291  0.008575     0.03794  0.037940   \n",
       "0.00005                  0.001978  0.003703  0.005484     0.02981  0.032520   \n",
       "\n",
       "                        valid_loss_epoch_14                      \n",
       "batch_size           16                  8         12        16  \n",
       "learning_rate                                                    \n",
       "0.00002        0.041554            0.023577  0.038378  0.051685  \n",
       "0.00003        0.042457            0.020008  0.035016  0.051646  \n",
       "0.00005        0.029810            0.017364  0.028062  0.040583  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table([\"train_loss_epoch_14\", \"valid_loss_epoch_14\", \"val_hamming\"], index = \"learning_rate\", columns=\"batch_size\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial grid analysis of MACRO DETERMINANT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"grid_results_determinants_macro.json\") as f:\n",
    "    grids = json.load(f)\n",
    "    \n",
    "grids = grids[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_df = grid_dicto_to_df_list(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max-len</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>train_loss_epoch_1</th>\n",
       "      <th>valid_loss_epoch_1</th>\n",
       "      <th>f1_epoch_1</th>\n",
       "      <th>accuracy_epoch_1</th>\n",
       "      <th>roc_auc_epoch_1</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy_epoch_14</th>\n",
       "      <th>roc_auc_epoch_14</th>\n",
       "      <th>hamming_epoch_14</th>\n",
       "      <th>proba_outputs_epoch_14</th>\n",
       "      <th>actual_classes_epoch_14</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_hamming</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.523061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.754679</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>[[[0.19750072062015533, 0.010183245874941349, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1....</td>\n",
       "      <td>0.311415</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.671966</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.178121</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.800134</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>[[[0.48576849699020386, 0.015220322646200657, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1....</td>\n",
       "      <td>0.396041</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.591823</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.029140</td>\n",
       "      <td>0.180109</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.758690</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>[[[0.2876509726047516, 0.015411117114126682, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1....</td>\n",
       "      <td>0.440892</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.663855</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.013780</td>\n",
       "      <td>0.102571</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.743984</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>[[[0.038321103900671005, 0.002660775789991021,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1....</td>\n",
       "      <td>0.256143</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.722907</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.020086</td>\n",
       "      <td>0.164308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.751337</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>[[[0.06443574279546738, 0.006163878366351128, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1....</td>\n",
       "      <td>0.420646</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.591823</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max-len  learning_rate  batch_size  num_train_epochs  n_epochs  \\\n",
       "0      128        0.00002           8                14        15   \n",
       "1      128        0.00002          12                14        15   \n",
       "2      128        0.00002          16                14        15   \n",
       "3      128        0.00003           8                14        15   \n",
       "4      128        0.00003          12                14        15   \n",
       "\n",
       "   train_loss_epoch_1  valid_loss_epoch_1  f1_epoch_1  accuracy_epoch_1  \\\n",
       "0            0.014829            0.106830    0.120000          0.055556   \n",
       "1            0.021178            0.178121    0.043478          0.000000   \n",
       "2            0.029140            0.180109    0.044444          0.027778   \n",
       "3            0.013780            0.102571    0.044444          0.027778   \n",
       "4            0.020086            0.164308    0.000000          0.000000   \n",
       "\n",
       "   roc_auc_epoch_1  ...  accuracy_epoch_14 roc_auc_epoch_14 hamming_epoch_14  \\\n",
       "0         0.523061  ...           0.500000         0.754679         0.150000   \n",
       "1         0.507687  ...           0.583333         0.800134         0.127778   \n",
       "2         0.511364  ...           0.500000         0.758690         0.155556   \n",
       "3         0.511364  ...           0.444444         0.743984         0.177778   \n",
       "4         0.500000  ...           0.472222         0.751337         0.166667   \n",
       "\n",
       "                              proba_outputs_epoch_14  \\\n",
       "0  [[[0.19750072062015533, 0.010183245874941349, ...   \n",
       "1  [[[0.48576849699020386, 0.015220322646200657, ...   \n",
       "2  [[[0.2876509726047516, 0.015411117114126682, 0...   \n",
       "3  [[[0.038321103900671005, 0.002660775789991021,...   \n",
       "4  [[[0.06443574279546738, 0.006163878366351128, ...   \n",
       "\n",
       "                             actual_classes_epoch_14  test_loss   test_f1  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1....   0.311415  0.511628   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1....   0.396041  0.380952   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1....   0.440892  0.500000   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1....   0.256143  0.590909   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1....   0.420646  0.380952   \n",
       "\n",
       "   test_roc_auc  test_hamming  test_accuracy  \n",
       "0      0.671966      0.233333       0.388889  \n",
       "1      0.591823      0.288889       0.277778  \n",
       "2      0.663855      0.266667       0.333333  \n",
       "3      0.722907      0.200000       0.388889  \n",
       "4      0.591823      0.288889       0.277778  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train_loss_epoch_14</th>\n",
       "      <th>valid_loss_epoch_14</th>\n",
       "      <th>f1_epoch_14</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_hamming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.101355</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.256143</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.086631</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.311415</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.111675</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.329757</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.255556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.205773</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.369603</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>12</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>0.140638</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.396041</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.288889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.160999</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.420646</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.288889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.160282</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.440892</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.190025</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.441840</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>16</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.180298</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.603788</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  batch_size  train_loss_epoch_14  valid_loss_epoch_14  \\\n",
       "3        0.00003           8             0.000648             0.101355   \n",
       "0        0.00002           8             0.001641             0.086631   \n",
       "6        0.00005           8             0.000315             0.111675   \n",
       "7        0.00005          12             0.000678             0.205773   \n",
       "1        0.00002          12             0.002858             0.140638   \n",
       "4        0.00003          12             0.001464             0.160999   \n",
       "2        0.00002          16             0.004041             0.160282   \n",
       "8        0.00005          16             0.001418             0.190025   \n",
       "5        0.00003          16             0.003038             0.180298   \n",
       "\n",
       "   f1_epoch_14  test_loss   test_f1  test_hamming  \n",
       "3     0.619048   0.256143  0.590909      0.200000  \n",
       "0     0.649351   0.311415  0.511628      0.233333  \n",
       "6     0.650602   0.329757  0.465116      0.255556  \n",
       "7     0.604651   0.369603  0.500000      0.266667  \n",
       "1     0.716049   0.396041  0.380952      0.288889  \n",
       "4     0.634146   0.420646  0.380952      0.288889  \n",
       "2     0.650000   0.440892  0.500000      0.266667  \n",
       "8     0.666667   0.441840  0.545455      0.222222  \n",
       "5     0.617284   0.603788  0.545455      0.222222  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_comparison = [\"learning_rate\", \"batch_size\" , \"train_loss_epoch_14\", \"valid_loss_epoch_14\", \"f1_epoch_14\", \"test_loss\", \"test_f1\", \"test_hamming\"]\n",
    "df[cols_comparison].sort_values([\"test_loss\"], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">train_loss_epoch_14</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valid_loss_epoch_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00002</th>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.086631</td>\n",
       "      <td>0.140638</td>\n",
       "      <td>0.160282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00003</th>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.101355</td>\n",
       "      <td>0.160999</td>\n",
       "      <td>0.180298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00005</th>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.111675</td>\n",
       "      <td>0.205773</td>\n",
       "      <td>0.190025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train_loss_epoch_14                     valid_loss_epoch_14  \\\n",
       "batch_size                     8         12        16                  8    \n",
       "learning_rate                                                               \n",
       "0.00002                  0.001641  0.002858  0.004041            0.086631   \n",
       "0.00003                  0.000648  0.001464  0.003038            0.101355   \n",
       "0.00005                  0.000315  0.000678  0.001418            0.111675   \n",
       "\n",
       "                                   \n",
       "batch_size           12        16  \n",
       "learning_rate                      \n",
       "0.00002        0.140638  0.160282  \n",
       "0.00003        0.160999  0.180298  \n",
       "0.00005        0.205773  0.190025  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table([\"train_loss_epoch_14\", \"valid_loss_epoch_14\"], index = \"learning_rate\", columns=\"batch_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">train_loss_epoch_14</th>\n",
       "      <th colspan=\"3\" halign=\"left\">val_hamming</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valid_loss_epoch_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00002</th>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.086631</td>\n",
       "      <td>0.140638</td>\n",
       "      <td>0.160282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00003</th>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>0.101355</td>\n",
       "      <td>0.160999</td>\n",
       "      <td>0.180298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00005</th>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.172222</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.111675</td>\n",
       "      <td>0.205773</td>\n",
       "      <td>0.190025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train_loss_epoch_14                     val_hamming            \\\n",
       "batch_size                     8         12        16          8         12   \n",
       "learning_rate                                                                 \n",
       "0.00002                  0.001641  0.002858  0.004041    0.144444  0.150000   \n",
       "0.00003                  0.000648  0.001464  0.003038    0.155556  0.177778   \n",
       "0.00005                  0.000315  0.000678  0.001418    0.166667  0.172222   \n",
       "\n",
       "                        valid_loss_epoch_14                      \n",
       "batch_size           16                  8         12        16  \n",
       "learning_rate                                                    \n",
       "0.00002        0.144444            0.086631  0.140638  0.160282  \n",
       "0.00003        0.161111            0.101355  0.160999  0.180298  \n",
       "0.00005        0.155556            0.111675  0.205773  0.190025  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table([\"train_loss_epoch_14\", \"valid_loss_epoch_14\", \"val_hamming\"], index = \"learning_rate\", columns=\"batch_size\")\n",
    "\n",
    "#  Hamming loss is the fraction of labels that are incorrectly predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial grid analysis of MACRO CONTENT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"grid_results_contents_macro.json\") as f:\n",
    "    grids = json.load(f)\n",
    "\n",
    "grids = grids[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_df = grid_dicto_to_df_list(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['max-len', 'learning_rate', 'batch_size', 'num_train_epochs',\n",
       "       'n_epochs', 'train_loss_epoch_1', 'valid_loss_epoch_1', 'f1_epoch_1',\n",
       "       'accuracy_epoch_1', 'roc_auc_epoch_1',\n",
       "       ...\n",
       "       'accuracy_epoch_14', 'roc_auc_epoch_14', 'hamming_epoch_14',\n",
       "       'proba_outputs_epoch_14', 'actual_classes_epoch_14', 'test_loss',\n",
       "       'test_f1', 'test_roc_auc', 'test_hamming', 'test_accuracy'],\n",
       "      dtype='object', length=129)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max-len</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>train_loss_epoch_1</th>\n",
       "      <th>valid_loss_epoch_1</th>\n",
       "      <th>f1_epoch_1</th>\n",
       "      <th>accuracy_epoch_1</th>\n",
       "      <th>roc_auc_epoch_1</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy_epoch_14</th>\n",
       "      <th>roc_auc_epoch_14</th>\n",
       "      <th>hamming_epoch_14</th>\n",
       "      <th>proba_outputs_epoch_14</th>\n",
       "      <th>actual_classes_epoch_14</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_hamming</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.013434</td>\n",
       "      <td>0.075877</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.521839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.850550</td>\n",
       "      <td>0.047980</td>\n",
       "      <td>[[[0.9560956358909607, 0.022482305765151978, 0...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.044833</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.855142</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.019257</td>\n",
       "      <td>0.127115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.808288</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>[[[0.9606870412826538, 0.03840835019946098, 0....</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.075901</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.857546</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.027511</td>\n",
       "      <td>0.153129</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.539429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.789578</td>\n",
       "      <td>0.065657</td>\n",
       "      <td>[[[0.9148823022842407, 0.06423570215702057, 0....</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.098565</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.811664</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.060665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.891100</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>[[[0.9746949672698975, 0.015561840496957302, 0...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.903428</td>\n",
       "      <td>0.034632</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.132107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.841755</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>[[[0.9690043926239014, 0.017071973532438278, 0...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.065283</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.859950</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max-len  learning_rate  batch_size  num_train_epochs  n_epochs  \\\n",
       "0      128        0.00002           8                14        15   \n",
       "1      128        0.00002          12                14        15   \n",
       "2      128        0.00002          16                14        15   \n",
       "3      128        0.00003           8                14        15   \n",
       "4      128        0.00003          12                14        15   \n",
       "\n",
       "   train_loss_epoch_1  valid_loss_epoch_1  f1_epoch_1  accuracy_epoch_1  \\\n",
       "0            0.013434            0.075877    0.086957          0.055556   \n",
       "1            0.019257            0.127115    0.000000          0.000000   \n",
       "2            0.027511            0.153129    0.153846          0.111111   \n",
       "3            0.010332            0.060665    0.000000          0.000000   \n",
       "4            0.020979            0.132107    0.000000          0.000000   \n",
       "\n",
       "   roc_auc_epoch_1  ...  accuracy_epoch_14 roc_auc_epoch_14 hamming_epoch_14  \\\n",
       "0         0.521839  ...           0.666667         0.850550         0.047980   \n",
       "1         0.500000  ...           0.583333         0.808288         0.050505   \n",
       "2         0.539429  ...           0.555556         0.789578         0.065657   \n",
       "3         0.500000  ...           0.777778         0.891100         0.030303   \n",
       "4         0.500000  ...           0.666667         0.841755         0.045455   \n",
       "\n",
       "                              proba_outputs_epoch_14  \\\n",
       "0  [[[0.9560956358909607, 0.022482305765151978, 0...   \n",
       "1  [[[0.9606870412826538, 0.03840835019946098, 0....   \n",
       "2  [[[0.9148823022842407, 0.06423570215702057, 0....   \n",
       "3  [[[0.9746949672698975, 0.015561840496957302, 0...   \n",
       "4  [[[0.9690043926239014, 0.017071973532438278, 0...   \n",
       "\n",
       "                             actual_classes_epoch_14  test_loss   test_f1  \\\n",
       "0  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.044833  0.739130   \n",
       "1  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.075901  0.755556   \n",
       "2  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.098565  0.681818   \n",
       "3  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.038050  0.826087   \n",
       "4  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.065283  0.772727   \n",
       "\n",
       "   test_roc_auc  test_hamming  test_accuracy  \n",
       "0      0.855142      0.051948       0.619048  \n",
       "1      0.857546      0.047619       0.619048  \n",
       "2      0.811664      0.060606       0.476190  \n",
       "3      0.903428      0.034632       0.714286  \n",
       "4      0.859950      0.043290       0.666667  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train_loss_epoch_14</th>\n",
       "      <th>valid_loss_epoch_14</th>\n",
       "      <th>f1_epoch_14</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_hamming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.030701</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.030832</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.028789</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.034632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.044833</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.051948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.042242</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.045474</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>12</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.065283</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.043290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.058163</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.069214</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.051813</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.075901</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>16</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.065976</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.084727</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.051948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.072391</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.098565</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  batch_size  train_loss_epoch_14  valid_loss_epoch_14  \\\n",
       "6        0.00005           8             0.000889             0.030701   \n",
       "3        0.00003           8             0.001269             0.028789   \n",
       "0        0.00002           8             0.001962             0.030636   \n",
       "7        0.00005          12             0.001572             0.042242   \n",
       "4        0.00003          12             0.002406             0.044004   \n",
       "8        0.00005          16             0.002653             0.058163   \n",
       "1        0.00002          12             0.003683             0.051813   \n",
       "5        0.00003          16             0.004675             0.065976   \n",
       "2        0.00002          16             0.006812             0.072391   \n",
       "\n",
       "   f1_epoch_14  test_loss   test_f1  test_hamming  \n",
       "6     0.814815   0.030832  0.851064      0.030303  \n",
       "3     0.850000   0.038050  0.826087      0.034632  \n",
       "0     0.765432   0.044833  0.739130      0.051948  \n",
       "7     0.809524   0.045474  0.844444      0.030303  \n",
       "4     0.769231   0.065283  0.772727      0.043290  \n",
       "8     0.759494   0.069214  0.755556      0.047619  \n",
       "1     0.729730   0.075901  0.755556      0.047619  \n",
       "5     0.763158   0.084727  0.739130      0.051948  \n",
       "2     0.666667   0.098565  0.681818      0.060606  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_comparison = [\"learning_rate\", \"batch_size\" , \"train_loss_epoch_14\", \"valid_loss_epoch_14\", \"f1_epoch_14\", \"test_loss\", \"test_f1\", \"test_hamming\"]\n",
    "df[cols_comparison].sort_values([\"test_loss\"], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">train_loss_epoch_14</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valid_loss_epoch_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00002</th>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.051813</td>\n",
       "      <td>0.072391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00003</th>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.028789</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>0.065976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00005</th>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.030701</td>\n",
       "      <td>0.042242</td>\n",
       "      <td>0.058163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train_loss_epoch_14                     valid_loss_epoch_14  \\\n",
       "batch_size                     8         12        16                  8    \n",
       "learning_rate                                                               \n",
       "0.00002                  0.001962  0.003683  0.006812            0.030636   \n",
       "0.00003                  0.001269  0.002406  0.004675            0.028789   \n",
       "0.00005                  0.000889  0.001572  0.002653            0.030701   \n",
       "\n",
       "                                   \n",
       "batch_size           12        16  \n",
       "learning_rate                      \n",
       "0.00002        0.051813  0.072391  \n",
       "0.00003        0.044004  0.065976  \n",
       "0.00005        0.042242  0.058163  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table([\"train_loss_epoch_14\", \"valid_loss_epoch_14\"], index = \"learning_rate\", columns=\"batch_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">train_loss_epoch_14</th>\n",
       "      <th colspan=\"3\" halign=\"left\">val_hamming</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valid_loss_epoch_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00002</th>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.047980</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>0.065657</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.051813</td>\n",
       "      <td>0.072391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00003</th>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.028789</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>0.065976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00005</th>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.047980</td>\n",
       "      <td>0.030701</td>\n",
       "      <td>0.042242</td>\n",
       "      <td>0.058163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train_loss_epoch_14                     val_hamming            \\\n",
       "batch_size                     8         12        16          8         12   \n",
       "learning_rate                                                                 \n",
       "0.00002                  0.001962  0.003683  0.006812    0.047980  0.050505   \n",
       "0.00003                  0.001269  0.002406  0.004675    0.027778  0.045455   \n",
       "0.00005                  0.000889  0.001572  0.002653    0.035354  0.040404   \n",
       "\n",
       "                        valid_loss_epoch_14                      \n",
       "batch_size           16                  8         12        16  \n",
       "learning_rate                                                    \n",
       "0.00002        0.065657            0.030636  0.051813  0.072391  \n",
       "0.00003        0.045455            0.028789  0.044004  0.065976  \n",
       "0.00005        0.047980            0.030701  0.042242  0.058163  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table([\"train_loss_epoch_14\", \"valid_loss_epoch_14\", \"val_hamming\"], index = \"learning_rate\", columns=\"batch_size\")\n",
    "\n",
    "#  Hamming loss is the fraction of labels that are incorrectly predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD, KEEPING IN CASE WE NEED IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_curves = df.pivot_table([\"train_loss\", \"valid_loss\"], [\"max-len\", \"learning_rate\", \"batch_size\"], \"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">train_loss</th>\n",
       "      <th colspan=\"2\" halign=\"left\">valid_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max-len</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">128</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.00002</th>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.00003</th>\n",
       "      <th>8</th>\n",
       "      <td>0.001431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028542</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.00005</th>\n",
       "      <th>8</th>\n",
       "      <td>0.001059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 train_loss           valid_loss          \n",
       "epoch                                    13        14         13        14\n",
       "max-len learning_rate batch_size                                          \n",
       "128     0.00002       8                 NaN  0.001962        NaN  0.030636\n",
       "                      12                NaN  0.003683        NaN  0.051813\n",
       "                      16                NaN  0.006812        NaN  0.072391\n",
       "        0.00003       8            0.001431       NaN   0.028542       NaN\n",
       "                      12                NaN  0.002406        NaN  0.044004\n",
       "                      16                NaN  0.004675        NaN  0.065976\n",
       "        0.00005       8            0.001059       NaN   0.025364       NaN\n",
       "                      12                NaN  0.001572        NaN  0.042242\n",
       "                      16                NaN  0.002653        NaN  0.058163"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epoch\n",
       "13         NaN\n",
       "14    0.001962\n",
       "Name: (128, 2e-05, 8), dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_curves.iloc[0][\"train_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epoch\n",
       "13         NaN\n",
       "14    0.030636\n",
       "Name: (128, 2e-05, 8), dtype: float64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_curves.iloc[0][\"valid_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[190], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m train_loss_array \u001b[38;5;241m=\u001b[39m col[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m valid_loss_array \u001b[38;5;241m=\u001b[39m col[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvalid_loss_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.1\u001b[39m:\n\u001b[0;32m      8\u001b[0m     candidates\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_loss_array)\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "candidates = []\n",
    "\n",
    "for row, col in lr_curves.iterrows():\n",
    "\n",
    "    train_loss_array = col[\"train_loss\"]\n",
    "    valid_loss_array = col[\"valid_loss\"]\n",
    "    if valid_loss_array[2] < 0.1:\n",
    "        candidates.append(row)\n",
    "        print(\"train_loss\", train_loss_array)\n",
    "        print(\"valid_loss\", valid_loss_array)\n",
    "        print(row)\n",
    "        epochs = [2, 3, 4, 5, 6, 8]\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_ylim(0,0.2)\n",
    "        plt.plot(epochs, train_loss_array, label=\"train\")\n",
    "        plt.legend()\n",
    "        plt.plot(epochs, valid_loss_array, label=\"valid\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # train_loss_array = df.iloc[][\"train_loss\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(128, 1e-05, 8),\n",
       " (128, 2e-05, 8),\n",
       " (128, 3e-05, 8),\n",
       " (128, 5e-05, 8),\n",
       " (256, 1e-05, 8)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max-len</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>val_hamming</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_hamming</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.055640</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.832267</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.766444</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.020428</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.737737</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.019141</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.943049</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.737737</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.756968</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max-len  learning_rate  batch_size  num_train_epochs  epoch  train_loss  \\\n",
       "5       128        0.00001           8                 8      8    0.008330   \n",
       "35      128        0.00002           8                 8      8    0.003166   \n",
       "65      128        0.00003           8                 8      8    0.003359   \n",
       "95      128        0.00005           8                 8      8    0.001233   \n",
       "\n",
       "    valid_loss   val_acc    val_f1  val_roc_auc  val_hamming   test_f1  \\\n",
       "5     0.055640  0.555556  0.776471     0.832267     0.105556  0.654545   \n",
       "35    0.020428  0.944444  0.967033     0.968085     0.016667  0.625000   \n",
       "65    0.019141  0.888889  0.933333     0.943049     0.033333  0.625000   \n",
       "95    0.011852  0.972222  0.978261     0.978723     0.011111  0.653061   \n",
       "\n",
       "    test_roc_auc  test_hamming  test_accuracy  \n",
       "5       0.766444      0.200000       0.421053  \n",
       "35      0.737737      0.189474       0.526316  \n",
       "65      0.737737      0.189474       0.473684  \n",
       "95      0.756968      0.178947       0.526316  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"batch_size\"] == 8) & (df[\"max-len\"] == 128) & (df[\"epoch\"] == 8) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max-len</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>val_hamming</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_hamming</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.795429</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.006915</td>\n",
       "      <td>0.044345</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.953687</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.768952</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>0.045522</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.875460</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.744983</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010534</td>\n",
       "      <td>0.072114</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.810350</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.756968</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.744983</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>256</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050509</td>\n",
       "      <td>0.251619</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.227778</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.611761</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.160217</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.676372</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.587514</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.105277</td>\n",
       "      <td>0.615193</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.509998</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>0.510591</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.099104</td>\n",
       "      <td>0.568799</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.650136</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.570513</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.101223</td>\n",
       "      <td>0.585429</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.588226</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.560758</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max-len  learning_rate  batch_size  num_train_epochs  epoch  train_loss  \\\n",
       "64       128        0.00003           8                 6      6    0.003388   \n",
       "70       128        0.00003          12                 6      6    0.006915   \n",
       "62       128        0.00003           8                 4      4    0.007464   \n",
       "61       128        0.00003           8                 3      3    0.010534   \n",
       "93       128        0.00005           8                 5      5    0.003343   \n",
       "..       ...            ...         ...               ...    ...         ...   \n",
       "139      256        0.00001          32                 3      3    0.050509   \n",
       "96       128        0.00005          12                 2      2    0.017911   \n",
       "25       128        0.00001          64                 3      3    0.105277   \n",
       "24       128        0.00001          64                 2      2    0.099104   \n",
       "26       128        0.00001          64                 4      4    0.101223   \n",
       "\n",
       "     valid_loss   val_acc    val_f1  val_roc_auc  val_hamming   test_f1  \\\n",
       "64     0.020360  0.916667  0.955556     0.957447     0.022222  0.705882   \n",
       "70     0.044345  0.861111  0.945055     0.953687     0.027778  0.666667   \n",
       "62     0.045522  0.694444  0.847059     0.875460     0.072222  0.638298   \n",
       "61     0.072114  0.527778  0.735632     0.810350     0.127778  0.653061   \n",
       "93     0.017779  0.944444  0.967033     0.968085     0.016667  0.638298   \n",
       "..          ...       ...       ...          ...          ...       ...   \n",
       "139    0.251619  0.111111  0.226415     0.563830     0.227778  0.475000   \n",
       "96     0.160217  0.138889  0.521739     0.676372     0.244444  0.459770   \n",
       "25     0.615193  0.055556  0.076923     0.509998     0.266667  0.385542   \n",
       "24     0.568799  0.361111  0.473684     0.650136     0.222222  0.451613   \n",
       "26     0.585429  0.138889  0.310345     0.588226     0.222222  0.448980   \n",
       "\n",
       "     test_roc_auc  test_hamming  test_accuracy  \n",
       "64       0.795429      0.157895       0.578947  \n",
       "70       0.768952      0.178947       0.578947  \n",
       "62       0.744983      0.178947       0.526316  \n",
       "61       0.756968      0.178947       0.526316  \n",
       "93       0.744983      0.178947       0.526316  \n",
       "..            ...           ...            ...  \n",
       "139      0.611761      0.442105       0.000000  \n",
       "96       0.587514      0.494737       0.052632  \n",
       "25       0.510591      0.536842       0.000000  \n",
       "24       0.570513      0.536842       0.000000  \n",
       "26       0.560758      0.568421       0.000000  \n",
       "\n",
       "[144 rows x 15 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"test_hamming\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df.pivot_table(\"train_loss\", index=\"batch_size\", columns=\"epoch\")\n",
    "sns.lineplot(df.pivot_table(\"train_loss\", index=\"batch_size\", columns=\"learning_rate\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>learning_rate</th>\n",
       "      <th>0.00001</th>\n",
       "      <th>0.00002</th>\n",
       "      <th>0.00003</th>\n",
       "      <th>0.00005</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.520028</td>\n",
       "      <td>0.738285</td>\n",
       "      <td>0.826715</td>\n",
       "      <td>0.869408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.427065</td>\n",
       "      <td>0.642209</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.857169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.426024</td>\n",
       "      <td>0.587445</td>\n",
       "      <td>0.759086</td>\n",
       "      <td>0.798104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.233890</td>\n",
       "      <td>0.488532</td>\n",
       "      <td>0.478817</td>\n",
       "      <td>0.673709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.213279</td>\n",
       "      <td>0.102280</td>\n",
       "      <td>0.283535</td>\n",
       "      <td>0.332741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "learning_rate   0.00001   0.00002   0.00003   0.00005\n",
       "batch_size                                           \n",
       "8              0.520028  0.738285  0.826715  0.869408\n",
       "12             0.427065  0.642209  0.743243  0.857169\n",
       "16             0.426024  0.587445  0.759086  0.798104\n",
       "32             0.233890  0.488532  0.478817  0.673709\n",
       "64             0.213279  0.102280  0.283535  0.332741"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(\"val_f1\", index=\"batch_size\", columns=\"learning_rate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>batch_size</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.397769</td>\n",
       "      <td>0.275991</td>\n",
       "      <td>0.179460</td>\n",
       "      <td>0.116576</td>\n",
       "      <td>0.128838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.562559</td>\n",
       "      <td>0.474716</td>\n",
       "      <td>0.467968</td>\n",
       "      <td>0.417302</td>\n",
       "      <td>0.078054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.648343</td>\n",
       "      <td>0.577810</td>\n",
       "      <td>0.592837</td>\n",
       "      <td>0.345786</td>\n",
       "      <td>0.245330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.806255</td>\n",
       "      <td>0.681425</td>\n",
       "      <td>0.727027</td>\n",
       "      <td>0.416070</td>\n",
       "      <td>0.259265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.802935</td>\n",
       "      <td>0.776245</td>\n",
       "      <td>0.535925</td>\n",
       "      <td>0.180425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.914928</td>\n",
       "      <td>0.903223</td>\n",
       "      <td>0.852483</td>\n",
       "      <td>0.698947</td>\n",
       "      <td>0.505840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "batch_size              8         12        16        32        64\n",
       "num_train_epochs                                                  \n",
       "2                 0.397769  0.275991  0.179460  0.116576  0.128838\n",
       "3                 0.562559  0.474716  0.467968  0.417302  0.078054\n",
       "4                 0.648343  0.577810  0.592837  0.345786  0.245330\n",
       "5                 0.806255  0.681425  0.727027  0.416070  0.259265\n",
       "6                 0.839503  0.802935  0.776245  0.535925  0.180425\n",
       "8                 0.914928  0.903223  0.852483  0.698947  0.505840"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(\"train_loss\", index=\"num_train_epochs\", columns=\"batch_size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the batch size, the more epochs we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>learning_rate</th>\n",
       "      <th>0.00001</th>\n",
       "      <th>0.00002</th>\n",
       "      <th>0.00003</th>\n",
       "      <th>0.00005</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444884</td>\n",
       "      <td>0.431269</td>\n",
       "      <td>0.494920</td>\n",
       "      <td>0.402652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452277</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.494995</td>\n",
       "      <td>0.554287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.437840</td>\n",
       "      <td>0.561055</td>\n",
       "      <td>0.549247</td>\n",
       "      <td>0.544104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.502723</td>\n",
       "      <td>0.529620</td>\n",
       "      <td>0.537557</td>\n",
       "      <td>0.613458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.490882</td>\n",
       "      <td>0.557319</td>\n",
       "      <td>0.578167</td>\n",
       "      <td>0.610236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.562151</td>\n",
       "      <td>0.570526</td>\n",
       "      <td>0.598490</td>\n",
       "      <td>0.583137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "learning_rate      0.00001   0.00002   0.00003   0.00005\n",
       "num_train_epochs                                        \n",
       "2                 0.444884  0.431269  0.494920  0.402652\n",
       "3                 0.452277  0.549296  0.494995  0.554287\n",
       "4                 0.437840  0.561055  0.549247  0.544104\n",
       "5                 0.502723  0.529620  0.537557  0.613458\n",
       "6                 0.490882  0.557319  0.578167  0.610236\n",
       "8                 0.562151  0.570526  0.598490  0.583137"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(\"val_loss\", index=\"num_train_epochs\", columns=\"learning_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the learning_rate, the less epochs we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>learning_rate</th>\n",
       "      <th>0.00001</th>\n",
       "      <th>0.00002</th>\n",
       "      <th>0.00003</th>\n",
       "      <th>0.00005</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444884</td>\n",
       "      <td>0.431269</td>\n",
       "      <td>0.494920</td>\n",
       "      <td>0.402652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452277</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.494995</td>\n",
       "      <td>0.554287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.437840</td>\n",
       "      <td>0.561055</td>\n",
       "      <td>0.549247</td>\n",
       "      <td>0.544104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.502723</td>\n",
       "      <td>0.529620</td>\n",
       "      <td>0.537557</td>\n",
       "      <td>0.613458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.490882</td>\n",
       "      <td>0.557319</td>\n",
       "      <td>0.578167</td>\n",
       "      <td>0.610236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.562151</td>\n",
       "      <td>0.570526</td>\n",
       "      <td>0.598490</td>\n",
       "      <td>0.583137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "learning_rate      0.00001   0.00002   0.00003   0.00005\n",
       "num_train_epochs                                        \n",
       "2                 0.444884  0.431269  0.494920  0.402652\n",
       "3                 0.452277  0.549296  0.494995  0.554287\n",
       "4                 0.437840  0.561055  0.549247  0.544104\n",
       "5                 0.502723  0.529620  0.537557  0.613458\n",
       "6                 0.490882  0.557319  0.578167  0.610236\n",
       "8                 0.562151  0.570526  0.598490  0.583137"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(\"test_f1\", index=\"num_train_epochs\", columns=\"learning_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>learning_rate</th>\n",
       "      <th>0.00001</th>\n",
       "      <th>0.00002</th>\n",
       "      <th>0.00003</th>\n",
       "      <th>0.00005</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.187801</td>\n",
       "      <td>0.103042</td>\n",
       "      <td>0.262815</td>\n",
       "      <td>0.368967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.253235</td>\n",
       "      <td>0.422490</td>\n",
       "      <td>0.476080</td>\n",
       "      <td>0.630595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.248223</td>\n",
       "      <td>0.557739</td>\n",
       "      <td>0.641010</td>\n",
       "      <td>0.715490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.397212</td>\n",
       "      <td>0.583765</td>\n",
       "      <td>0.743380</td>\n",
       "      <td>0.796062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.522570</td>\n",
       "      <td>0.625181</td>\n",
       "      <td>0.701280</td>\n",
       "      <td>0.831862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.675820</td>\n",
       "      <td>0.778283</td>\n",
       "      <td>0.885111</td>\n",
       "      <td>0.894382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "learning_rate      0.00001   0.00002   0.00003   0.00005\n",
       "num_train_epochs                                        \n",
       "2                 0.187801  0.103042  0.262815  0.368967\n",
       "3                 0.253235  0.422490  0.476080  0.630595\n",
       "4                 0.248223  0.557739  0.641010  0.715490\n",
       "5                 0.397212  0.583765  0.743380  0.796062\n",
       "6                 0.522570  0.625181  0.701280  0.831862\n",
       "8                 0.675820  0.778283  0.885111  0.894382"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(\"val_f1\", index=\"num_train_epochs\", columns=\"learning_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curve plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dont gridsearch epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
